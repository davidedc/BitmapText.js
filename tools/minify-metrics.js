#!/usr/bin/env node

/**
 * ‚ö†Ô∏è  THIS IS A BUNDLED/BUILT FILE - DO NOT EDIT ‚ö†Ô∏è
 *
 * Metrics Minifier - Processes full metrics files and outputs minified versions
 *
 * This file is automatically generated by concatenating multiple source files.
 * It uses the EXACT SAME CODE as the font-assets-builder page for minification
 * and roundtrip verification, ensuring identical behavior.
 *
 * Source files concatenated (in dependency order):
 *   1. src/runtime/CHARACTER_SET.js - Character set constant (204 chars)
 *   2. src/runtime/FontMetrics.js - FontMetrics class
 *   3. src/builder/MetricsMinifier.js - Minification logic
 *   4. src/builder/MetricsExpander.js - Expansion for roundtrip
 *   5. src/utils/deep-equal.js - Deep equality comparison
 *
 * Purpose:
 *   - Find all *-full.js files in font-assets/
 *   - Extract full metricsData from each file
 *   - Run MetricsMinifier.minifyWithVerification() (includes roundtrip check)
 *   - Output minified .js files as *-full-minified.js
 *   - Report statistics and verification results
 *
 * Usage:
 *   ./tools/minify-metrics.js [options]
 *   node tools/minify-metrics.js [options]
 *
 * Options:
 *   --verify-exact    Compare output with production metrics-*.js files (byte-for-byte)
 *   --help, -h        Show this help message
 *
 * Input:  font-assets/metrics-...-full.js (full metrics from font-assets-builder)
 * Output: font-assets/metrics-...-full-minified.js (minified .js files)
 *
 * To rebuild this tool:
 *   ./scripts/build-metrics-minifier.sh
 *
 * Generated by: scripts/build-metrics-minifier.sh
 */

// ============================================================================
// NODE.JS BUILT-IN MODULES
// ============================================================================

const fs = require('fs');
const path = require('path');

// ============================================================================
// COMMAND-LINE ARGUMENT PARSING
// ============================================================================

const args = process.argv.slice(2);
const options = {
  verifyExact: args.includes('--verify-exact'),
  help: args.includes('--help') || args.includes('-h')
};

if (options.help) {
  console.log(`
Metrics Minifier - Test minification strategies on full metrics files

Usage:
  ./tools/minify-metrics.js [options]
  node tools/minify-metrics.js [options]

Options:
  --verify-exact    Compare output with production metrics-*.js files
                    Performs byte-for-byte comparison to verify node script
                    produces identical output to browser font-assets-builder
                    (useful for validating the tool, not for testing new strategies)

  --help, -h        Show this help message

Description:
  Processes all *-full.js files in font-assets/ directory:
  1. Extracts full metricsData from each file
  2. Runs MetricsMinifier.minifyWithVerification() (includes roundtrip check)
  3. Outputs minified .js files as *-full-minified.js
  4. Reports statistics and verification results

  The tool uses the EXACT same minification code as the browser
  font-assets-builder page, ensuring identical behavior.

Prerequisites:
  Generate *-full.js files first:
  1. Open public/font-assets-builder.html in browser
  2. Configure font settings
  3. Check "Include non-minified metrics files"
  4. Click "Download font assets"
  5. Extract fontAssets.zip to font-assets/

Examples:
  # Standard usage (no comparison with production files)
  ./tools/minify-metrics.js

  # Verify output matches production files exactly
  ./tools/minify-metrics.js --verify-exact

Development Workflow:
  # Test new minification strategy
  1. Edit src/builder/MetricsMinifier.js
  2. ./scripts/build-metrics-minifier.sh
  3. ./tools/minify-metrics.js
  4. Examine *-full-minified.js output files
`);
  process.exit(0);
}

// ============================================================================
// CHARACTER SET CONSTANT
// Required by both MetricsMinifier and MetricsExpander
// ============================================================================

// CHARACTER SET CONSTANT - 204 characters
// Used by both build-time (MetricsMinifier) and runtime (MetricsExpander)
//
// This is the sorted character set that defines the standard order for all font metrics.
// ALL font files must contain exactly these 204 characters in this order.

// Generate character set programmatically
function generateCharacterSet() {
  const chars = [];

  // ASCII printable characters (32-126)
  // Includes space, numbers, letters, and common symbols
  for (let i = 32; i <= 126; i++) {
    chars.push(String.fromCharCode(i));
  }

  // A selection from Windows-1252 (CP-1252) printable characters.
  // This is the most standard definition of "extended ASCII codes" from 128 to 159
  // and many of these are common/useful symbols that people "expect to have".
  // However fromCharCode doesn't work on those as that range is not defined
  // in UTF-8/Unicode (modern web standard, so we want to include (some of) them but we have
  // to map them to specific Unicode code points, not the byte values themselves.
  // NOTE: we could likely shave some of these off, as they are not easily printable
  // in Javascript and some of them are fairly arcane/
  const cp1252PrintableChars = [
    8364, // ‚Ç¨ Euro sign (CP-1252: 128)
    //  8218, // ‚Äö Single low-9 quotation mark (CP-1252: 130)
    //  402,  // ∆í Latin small letter f with hook (CP-1252: 131)
    //  8222, // ‚Äû Double low-9 quotation mark (CP-1252: 132)
    8230, // ‚Ä¶ Horizontal ellipsis (CP-1252: 133)
    //  8224, // ‚Ä† Dagger (CP-1252: 134)
    //  8225, // ‚Ä° Double dagger (CP-1252: 135)
    //  710,  // ÀÜ Modifier letter circumflex accent (CP-1252: 136)
    8240, // ‚Ä∞ Per mille sign (CP-1252: 137)
    //  352,  // ≈† Latin capital letter S with caron (CP-1252: 138)
    8249, // ‚Äπ Single left-pointing angle quotation (CP-1252: 139)
    //  338,  // ≈í Latin capital ligature OE (CP-1252: 140)
    381,  // ≈Ω Latin capital letter Z with caron (CP-1252: 142)
    //  8216, // ' Left single quotation mark (CP-1252: 145)

    // UNFORTUNATELY SOMETIMES USED INSTEAD OF APOSTROPHE
    8217, // ' ""curly apostrophe"" or "right single quotation mark" (CP-1252: 146)

    //  8220, // " Left double quotation mark (CP-1252: 147)
    //  8221, // " Right double quotation mark (CP-1252: 148)
    8226, // ‚Ä¢ Bullet (CP-1252: 149)
    //  8211, // ‚Äì En dash (CP-1252: 150)
    8212, // ‚Äî Em dash (CP-1252: 151)
    //  732,  // Àú Small tilde (CP-1252: 152)
    8482, // ‚Ñ¢ Trade mark sign (CP-1252: 153)
    353,  // ≈° Latin small letter S with caron (CP-1252: 154)
    8250, // ‚Ä∫ Single right-pointing angle quotation mark (CP-1252: 155)
    339,  // ≈ì Latin small ligature oe (CP-1252: 156)
    382,  // ≈æ Latin small letter z with caron (CP-1252: 158)
    376   // ≈∏ Latin capital letter Y with diaeresis (CP-1252: 159)
  ];

  for (const code of cp1252PrintableChars) {
    chars.push(String.fromCharCode(code));
  }

  // Latin-1 Supplement characters (161-255)
  // These are properly defined in UTF-8/Unicode
  // Exclude U+00AD (173) - soft hyphen, which has zero width
  for (let i = 161; i <= 255; i++) {
    if (i !== 173) { // Skip soft hyphen
      chars.push(String.fromCharCode(i));
    }
  }

  // Add Full Block character (allows us to see the maximum space taken by a glyph)
  chars.push('‚ñà');

  // Sort the character set (this is how it's used throughout the codebase)
  return chars.sort().join('');
}

// Export as constant
const CHARACTER_SET = generateCharacterSet();

// ============================================================================
// FONT METRICS CLASS
// Required by MetricsExpander for creating FontMetrics instances
// ============================================================================

// FontMetrics - Core Runtime Class
//
// This is a CORE RUNTIME class designed for minimal bundle size (~3-4KB).
// It encapsulates all metrics data for a single font configuration as an immutable domain object.
//
// DISTRIBUTION ROLE:
// - Part of "runtime-only" distribution for production applications
// - Extended by FontMetricsFAB for font assets building capabilities
// - Contains only essential metrics data and accessor methods
// - No font generation, validation, or optimization code
//
// ARCHITECTURE:
// - Immutable object representing all metrics for ONE font configuration
// - Pre-computed lookups for optimal performance during text rendering
// - Provides clean API without needing fontProperties passed to every method
// - Follows same immutable pattern as FontProperties
//
// SEPARATION RATIONALE:
// - Encapsulates related metrics data together
// - Eliminates repeated fontProperties parameter passing
// - Serves as domain object for font metrics
// - Enables cleaner, more object-oriented API
//
// For font assets building capabilities, use FontMetricsFAB which extends this class.
class FontMetrics {
  constructor(data, options = {}) {
    // Validate input data structure
    if (!data || typeof data !== 'object') {
      throw new Error('FontMetrics constructor requires data object');
    }
    
    // Kerning table: character pairs ‚Üí adjustment values
    this._kerningTable = data.kerningTable || {};
    
    // Character metrics: character ‚Üí TextMetrics-compatible object
    this._characterMetrics = data.characterMetrics || {};
    
    // Space advancement override for small font sizes
    this._spaceAdvancementOverride = data.spaceAdvancementOverrideForSmallSizesInPx || null;
    
    // Freeze for immutability (safe to use as value object)
    // Skip freezing if this is for font assets building (FAB)
    if (!options.mutable) {
      Object.freeze(this._kerningTable);
      Object.freeze(this._characterMetrics);
      Object.freeze(this);
    }
  }
  
  /**
   * Get text measurement metrics for a character
   * @param {string} char - Character (code point) to get metrics for
   * @returns {Object} TextMetrics-compatible object
   */
  getCharacterMetrics(char) {
    return this._characterMetrics[char];
  }
  
  /**
   * Get kerning adjustment between two characters
   * @param {string} leftChar - Left character in pair
   * @param {string} rightChar - Right character in pair  
   * @returns {number} Kerning adjustment value (0 if no adjustment)
   */
  getKerningAdjustment(leftChar, rightChar) {
    if (!leftChar || !rightChar) return 0;
    return this._kerningTable[leftChar]?.[rightChar] || 0;
  }
  
  /**
   * Check if glyph exists in this font
   * @param {string} char - Character (code point) to check
   * @returns {boolean} True if glyph has metrics
   */
  hasGlyph(char) {
    return char in this._characterMetrics;
  }
  
  /**
   * Get space advancement override for small font sizes
   * @returns {number|null} Override value in pixels, or null if no override
   */
  getSpaceAdvancementOverride() {
    return this._spaceAdvancementOverride;
  }
  
  /**
   * Get the complete kerning table (for compatibility/debugging)
   * @returns {Object} Complete kerning table
   */
  getKerningTable() {
    return this._kerningTable;
  }
  
  /**
   * Get all available characters in this font
   * @returns {string[]} Array of available characters
   */
  getAvailableCharacters() {
    return Object.keys(this._characterMetrics);
  }
  
}
// ============================================================================
// METRICS MINIFIER
// Tier 3-5 optimizations: 2D kerning, value indexing, tuplet deduplication
// ============================================================================

// Static utility class for minifying font metrics data (build-time only)
// Converts verbose object structures to compact format for smaller file sizes
// NOTE: Requires src/runtime/CHARACTER_SET.js to be loaded first

class MetricsMinifier {
  // Private constructor - prevent instantiation following Effective Java patterns
  constructor() {
    throw new Error('MetricsMinifier cannot be instantiated - use static methods');
  }
  
  /**
   * Minifies font metrics data for smaller file size
   * TIER 2 OPTIMIZATION: Array-based glyph encoding
   * TIER 3 OPTIMIZATION: Two-dimensional kerning range compression
   * TIER 4 OPTIMIZATION: Value indexing (replaces repeated metric values with indices)
   * TIER 5 OPTIMIZATION: Tuplet deduplication (deduplicates glyph index arrays)
   *
   * REQUIRES: metricsData.characterMetrics must contain ALL 204 characters from CHARACTER_SET
   *
   * @param {Object} metricsData - Full metrics object containing kerningTable, characterMetrics, etc.
   * @returns {Object} Minified metrics with 'kv', 'k', 'b', 'v', 't', 'g', 's'
   * @throws {Error} If not all 204 characters are present
   */
  static minify(metricsData) {
    // Validate that ALL 204 characters from CHARACTER_SET are present
    // Note: We DON'T use Object.keys() because JavaScript reorders numeric keys
    // Instead, we iterate through CHARACTER_SET and check each character exists
    const missingChars = [];
    for (const char of CHARACTER_SET) {
      if (!(char in metricsData.characterMetrics)) {
        missingChars.push(char);
      }
    }

    if (missingChars.length > 0) {
      throw new Error(
        `MetricsMinifier requires ALL 204 characters from CHARACTER_SET.\n` +
        `Missing ${missingChars.length} characters: ${missingChars.slice(0, 10).join(', ')}${missingChars.length > 10 ? '...' : ''}\n` +
        `Please ensure font-assets-builder generates ALL 204 characters.`
      );
    }

    // Check for extra characters not in CHARACTER_SET
    const extraChars = Object.keys(metricsData.characterMetrics).filter(
      char => !CHARACTER_SET.includes(char)
    );

    if (extraChars.length > 0) {
      throw new Error(
        `Font contains ${extraChars.length} characters not in CHARACTER_SET: ${extraChars.join(', ')}\n` +
        `Please update src/runtime/CHARACTER_SET.js to include these characters.`
      );
    }

    // TIER 4: Create value lookup table and indexed glyph arrays
    const { valueLookup, indexedGlyphs } = this.#createValueLookupTable(
      metricsData.characterMetrics
    );

    // TIER 4: Create kerning value lookup table and indexed kerning table
    const { kerningValueLookup, indexedKerningTable } = this.#createKerningValueLookupTable(
      metricsData.kerningTable
    );

    // TIER 5: Create tuplet lookup table and tuplet indices
    const { tupletLookup, tupletIndices } = this.#createTupletLookupTable(
      indexedGlyphs
    );

    // Minify with tuplet indexing (Tier 5 optimization)
    return {
      kv: kerningValueLookup,  // TIER 4: Kerning value lookup table
      k: indexedKerningTable,  // TIER 4: Kerning table with indexed values
      b: this.#extractMetricsCommonToAllCharacters(metricsData.characterMetrics),
      v: valueLookup,          // TIER 4: Glyph value lookup table
      t: tupletLookup,         // TIER 5: Tuplet lookup table (unique index arrays)
      g: tupletIndices,        // TIER 5: Now single integers (indices into 't'), not arrays!
      s: metricsData.spaceAdvancementOverrideForSmallSizesInPx
    };
  }

  /**
   * Minifies font metrics data with automatic roundtrip verification
   * This is the RECOMMENDED method for font-assets-builder to catch compression bugs immediately
   *
   * Process:
   * 1. Minify the metrics data
   * 2. Expand it back using MetricsExpander
   * 3. Compare expanded data with original
   * 4. Throw detailed error if mismatch (prevents broken font files)
   * 5. Return minified data if verification passes
   *
   * @param {Object} metricsData - Full metrics object containing kerningTable, characterMetrics, etc.
   * @returns {Object} Minified metrics with verified integrity
   * @throws {Error} If roundtrip verification fails
   */
  static minifyWithVerification(metricsData) {
    // Step 1: Minify
    const minified = this.minify(metricsData);

    // Step 2: Check if MetricsExpander is available
    if (typeof MetricsExpander === 'undefined') {
      console.warn('‚ö†Ô∏è  MetricsExpander not loaded - skipping roundtrip verification');
      return minified;
    }

    // Step 3: Expand back
    const expanded = MetricsExpander.expand(minified);

    // Step 4: Verify kerning table
    const originalKerning = metricsData.kerningTable;
    const expandedKerning = expanded._kerningTable;

    // Check all original kerning pairs
    for (const [leftChar, pairs] of Object.entries(originalKerning)) {
      if (!expandedKerning[leftChar]) {
        throw new Error(
          `Roundtrip verification failed: Missing left character "${leftChar}" in expanded kerning table.\n` +
          `This indicates a bug in MetricsMinifier compression or MetricsExpander expansion.`
        );
      }

      for (const [rightChar, value] of Object.entries(pairs)) {
        const expandedValue = expandedKerning[leftChar][rightChar];
        if (expandedValue !== value) {
          throw new Error(
            `Roundtrip verification failed: Kerning mismatch for "${leftChar}/${rightChar}".\n` +
            `Expected: ${value}, Got: ${expandedValue}\n` +
            `This indicates a bug in MetricsMinifier compression or MetricsExpander expansion.`
          );
        }
      }
    }

    // Check for extra kerning pairs in expanded (should not happen)
    for (const [leftChar, pairs] of Object.entries(expandedKerning)) {
      if (!originalKerning[leftChar]) {
        throw new Error(
          `Roundtrip verification failed: Extra left character "${leftChar}" in expanded kerning table.\n` +
          `This indicates a bug in MetricsExpander expansion.`
        );
      }

      for (const rightChar of Object.keys(pairs)) {
        if (!(rightChar in originalKerning[leftChar])) {
          throw new Error(
            `Roundtrip verification failed: Extra kerning pair "${leftChar}/${rightChar}" in expanded data.\n` +
            `This indicates a bug in MetricsExpander expansion.`
          );
        }
      }
    }

    // Step 5: Verify character metrics count
    const originalCharCount = Object.keys(metricsData.characterMetrics).length;
    const expandedCharCount = Object.keys(expanded._characterMetrics).length;

    if (originalCharCount !== expandedCharCount) {
      throw new Error(
        `Roundtrip verification failed: Character count mismatch.\n` +
        `Expected: ${originalCharCount}, Got: ${expandedCharCount}\n` +
        `This indicates a bug in MetricsMinifier or MetricsExpander.`
      );
    }

    // All checks passed!
    console.debug('‚úÖ Roundtrip verification passed - compression integrity verified');
    return minified;
  }

  /**
   * Extracts common metrics shared across all characters
   * so that we don't need to repeat these in the serialised file.
   * Extract these from the first character in CHARACTER_SET (space)
   * @private
   */
  static #extractMetricsCommonToAllCharacters(characterMetrics) {
    // Use first character from CHARACTER_SET (space character)
    const firstChar = CHARACTER_SET[0];
    const firstGlyph = characterMetrics[firstChar];

    return {
      fba: firstGlyph.fontBoundingBoxAscent,     // fontBoundingBoxAscent
      fbd: firstGlyph.fontBoundingBoxDescent,    // fontBoundingBoxDescent
      hb: firstGlyph.hangingBaseline,            // hangingBaseline
      ab: firstGlyph.alphabeticBaseline,         // alphabeticBaseline
      ib: firstGlyph.ideographicBaseline,        // ideographicBaseline
      pd: firstGlyph.pixelDensity                // pixelDensity (CRITICAL for atlas reconstruction)
    };
  }
  
  /**
   * Creates value lookup table and converts glyph metrics to indexed arrays with tuplet compression
   * TIER 4 OPTIMIZATION: Value indexing - replaces repeated metric values with indices
   * TIER 5 OPTIMIZATION: Tuplet compression - reduces tuplet length from 5 to 3/4/5 based on redundancy
   *
   * Strategy: Assign shortest indices to values with highest (occurrence_count √ó string_length)
   * This maximizes savings because frequently-occurring long values get 1-digit indices
   *
   * Tuplet compression:
   *   - Case C (3 elements): w===r AND l===d  ‚Üí  [w, l, a]
   *   - Case B (4 elements): w===r only       ‚Üí  [w, l, a, d]
   *   - Case A (5 elements): no compression   ‚Üí  [w, l, r, a, d]
   *
   * @param {Object} characterMetrics - Character metrics object with all 204 characters
   * @returns {Object} Object with valueLookup array and indexedGlyphs array (variable-length tuplets)
   * @private
   */
  static #createValueLookupTable(characterMetrics) {
    // Step 1: Collect all unique values and count occurrences
    const valueOccurrences = new Map(); // value -> count

    for (const char of CHARACTER_SET) {
      const glyph = characterMetrics[char];
      const values = [
        glyph.width,
        glyph.actualBoundingBoxLeft,
        glyph.actualBoundingBoxRight,
        glyph.actualBoundingBoxAscent,
        glyph.actualBoundingBoxDescent
      ];

      for (const value of values) {
        valueOccurrences.set(value, (valueOccurrences.get(value) || 0) + 1);
      }
    }

    // Step 2: Calculate scores and sort by savings potential
    // Score = occurrences √ó string_length (higher = more savings from short index)
    const valueScores = Array.from(valueOccurrences.entries()).map(([value, count]) => {
      const stringLength = JSON.stringify(value).length;
      const score = count * stringLength;
      return { value, count, stringLength, score };
    });

    // Sort by score DESCENDING (highest savings first)
    // Top 10 values get indices 0-9 (1 char)
    // Next 90 values get indices 10-99 (2 chars)
    // Remaining values get indices 100+ (3+ chars)
    valueScores.sort((a, b) => b.score - a.score);

    // Step 3: Create value lookup table (sorted by score)
    const valueLookup = valueScores.map(vs => vs.value);

    // Step 4: Create value-to-index map for fast lookup during indexing
    const valueToIndex = new Map();
    valueLookup.forEach((value, index) => {
      valueToIndex.set(value, index);
    });

    // Step 5: Convert glyph arrays to indices and compress tuplets (TIER 5)
    const indexedGlyphs = Array.from(CHARACTER_SET).map(char => {
      const glyph = characterMetrics[char];
      const indices = [
        valueToIndex.get(glyph.width),                      // 0: width
        valueToIndex.get(glyph.actualBoundingBoxLeft),      // 1: left
        valueToIndex.get(glyph.actualBoundingBoxRight),     // 2: right
        valueToIndex.get(glyph.actualBoundingBoxAscent),    // 3: ascent
        valueToIndex.get(glyph.actualBoundingBoxDescent)    // 4: descent
      ];

      // TIER 5: Tuplet compression based on redundancy patterns
      const widthEqualsRight = indices[0] === indices[2];   // w === r
      const leftEqualsDescent = indices[1] === indices[4];  // l === d

      if (widthEqualsRight && leftEqualsDescent) {
        // Case C: Both conditions met - compress to 3 elements [w, l, a]
        return [indices[0], indices[1], indices[3]];
      }
      else if (widthEqualsRight) {
        // Case B: Only width === right - compress to 4 elements [w, l, a, d]
        return [indices[0], indices[1], indices[3], indices[4]];
      }
      else {
        // Case A: No compression - keep all 5 elements [w, l, r, a, d]
        return indices;
      }
    });

    // Log compression statistics
    let caseC = 0, caseB = 0, caseA = 0;
    for (const tuplet of indexedGlyphs) {
      if (tuplet.length === 3) caseC++;
      else if (tuplet.length === 4) caseB++;
      else caseA++;
    }
    const savedIndices = 1020 - (caseC * 3 + caseB * 4 + caseA * 5);
    console.debug(`üóúÔ∏è  Tuplet compression: ${caseC} √ó 3-elem, ${caseB} √ó 4-elem, ${caseA} √ó 5-elem (saved ${savedIndices} indices)`);

    return {
      valueLookup,
      indexedGlyphs
    };
  }

  /**
   * Creates tuplet lookup table and replaces glyph index arrays with tuplet indices
   * TIER 5 OPTIMIZATION: Tuplet deduplication - many glyphs share identical index patterns
   *
   * Strategy: Assign shortest indices to tuplets with highest (JSON_length √ó occurrences)
   * This works on top of Tier 5a pattern compression (variable-length tuplets)
   *
   * @param {Array<Array<number>>} indexedGlyphs - Array of index tuplets (may be variable length 3-5)
   * @returns {Object} Object with tupletLookup array and tupletIndices array
   * @private
   */
  static #createTupletLookupTable(indexedGlyphs) {
    // Step 1: Collect unique tuplets and count occurrences
    const tupletOccurrences = new Map(); // JSON string -> {tuplet, count}

    for (const tuplet of indexedGlyphs) {
      const key = JSON.stringify(tuplet);
      if (!tupletOccurrences.has(key)) {
        tupletOccurrences.set(key, { tuplet, count: 0 });
      }
      tupletOccurrences.get(key).count++;
    }

    // Step 2: Calculate scores and sort by savings potential
    // Score = JSON_length √ó occurrences (higher = more savings from short index)
    const tupletScores = Array.from(tupletOccurrences.values()).map(({tuplet, count}) => {
      const stringLength = JSON.stringify(tuplet).length;
      const score = stringLength * count;
      return { tuplet, count, stringLength, score };
    });

    // Sort by score DESCENDING (highest savings first)
    // Top 10 tuplets get indices 0-9 (1 char each)
    // Next 90 tuplets get indices 10-99 (2 chars each)
    // Remaining tuplets get indices 100+ (3+ chars each)
    tupletScores.sort((a, b) => b.score - a.score);

    // Step 3: Create tuplet lookup table (sorted by score for optimal indexing)
    const tupletLookup = tupletScores.map(ts => ts.tuplet);

    // Step 4: Create tuplet-to-index map for fast lookup
    const tupletToIndex = new Map();
    tupletLookup.forEach((tuplet, index) => {
      const key = JSON.stringify(tuplet);
      tupletToIndex.set(key, index);
    });

    // Step 5: Convert glyph tuplets to single tuplet indices
    const tupletIndices = indexedGlyphs.map(tuplet => {
      const key = JSON.stringify(tuplet);
      return tupletToIndex.get(key);
    });

    // Log compression statistics
    const uniqueTuplets = tupletLookup.length;
    const totalGlyphs = indexedGlyphs.length;
    const deduplicationPercent = ((1 - uniqueTuplets / totalGlyphs) * 100).toFixed(1);

    console.debug(`üóúÔ∏è  Tuplet deduplication: ${totalGlyphs} glyphs ‚Üí ${uniqueTuplets} unique tuplets (${deduplicationPercent}% deduplicated)`);

    return {
      tupletLookup,
      tupletIndices
    };
  }

  /**
   * Creates kerning value lookup table and replaces kerning values with indices
   * TIER 4 OPTIMIZATION: Value indexing for kerning table
   *
   * Strategy: Same as glyph value indexing - assign shortest indices to values
   * with highest (occurrence_count √ó string_length)
   *
   * @param {Object} kerningTable - Original kerning table with numeric values
   * @returns {Object} Object with kerningValueLookup array and indexedKerningTable
   * @private
   */
  static #createKerningValueLookupTable(kerningTable) {
    // Step 1: Collect all unique kerning values and count occurrences
    const valueOccurrences = new Map();

    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      for (const [rightChar, value] of Object.entries(pairs)) {
        valueOccurrences.set(value, (valueOccurrences.get(value) || 0) + 1);
      }
    }

    // Step 2: Calculate scores and sort by savings potential
    const valueScores = Array.from(valueOccurrences.entries()).map(([value, count]) => {
      const stringLength = JSON.stringify(value).length;
      const score = count * stringLength;
      return { value, count, stringLength, score };
    });

    // Sort by score DESCENDING (highest savings first)
    valueScores.sort((a, b) => b.score - a.score);

    // Step 3: Create kerning value lookup table
    const kerningValueLookup = valueScores.map(vs => vs.value);

    // Step 4: Create value-to-index map
    const valueToIndex = new Map();
    kerningValueLookup.forEach((value, index) => {
      valueToIndex.set(value, index);
    });

    // Step 5: Apply 2D compression with indexed values
    // First, replace all values with indices
    const indexedTable = {};
    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      indexedTable[leftChar] = {};
      for (const [rightChar, value] of Object.entries(pairs)) {
        indexedTable[leftChar][rightChar] = valueToIndex.get(value);
      }
    }

    // Then apply 2D range compression on the indexed table
    const indexedKerningTable = this.#minifyKerningTable(indexedTable);

    return {
      kerningValueLookup,
      indexedKerningTable
    };
  }

  /**
   * Converts glyph metrics objects to compact arrays
   * TIER 2 OPTIMIZATION: Returns array of arrays (removes character keys, uses position instead)
   * Array format: [width, actualBoundingBoxLeft, actualBoundingBoxRight, actualBoundingBoxAscent, actualBoundingBoxDescent]
   * Always uses CHARACTER_SET order (all 204 characters)
   * @deprecated This method is replaced by #createValueLookupTable (Tier 4 optimization)
   * @private
   */
  static #minifyCharacterMetrics(characterMetrics) {
    // Convert to array of arrays in CHARACTER_SET order
    // IMPORTANT: Must iterate through CHARACTER_SET, not Object.keys/values
    // because JavaScript reorders numeric string keys ("0"-"9")
    return Array.from(CHARACTER_SET).map(char => {
      const glyph = characterMetrics[char];
      return [
        glyph.width,
        glyph.actualBoundingBoxLeft,
        glyph.actualBoundingBoxRight,
        glyph.actualBoundingBoxAscent,
        glyph.actualBoundingBoxDescent
      ];
    });
  }
  
  /**
   * Minifies kerning table using two-dimensional range notation
   * TIER 3 OPTIMIZATION: Two-pass compression
   *   Pass 1 (right-side): {"A":{"0":20,"1":20}} ‚Üí {"A":{"0-1":20}}
   *   Pass 2 (left-side):  {"A":{"s":20},"B":{"s":20}} ‚Üí {"A-B":{"s":20}}
   * Always uses CHARACTER_SET for range compression
   * @param {Object} kerningTable - Kerning table to minify
   * @private
   */
  static #minifyKerningTable(kerningTable) {
    // PASS 1: Compress right side (characters that follow)
    const rightCompressed = {};
    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      rightCompressed[leftChar] = this.#compressKerningPairs(pairs);
    }

    // PASS 2: Compress left side (characters that come before)
    const leftCompressed = this.#compressLeftSide(rightCompressed);

    return leftCompressed;
  }

  /**
   * Compresses kerning pairs by finding consecutive character ranges with same value
   * Always uses CHARACTER_SET for range compression
   * @param {Object} pairs - Kerning pairs like {"0":20,"1":20,"2":20,...}
   * @returns {Object} Compressed pairs like {"0-2":20}
   * @private
   */
  static #compressKerningPairs(pairs) {
    if (Object.keys(pairs).length === 0) return {};

    // Build map of value -> array of character indices
    const valueToIndices = {};

    for (const [char, value] of Object.entries(pairs)) {
      const index = CHARACTER_SET.indexOf(char);
      if (index === -1) {
        console.warn(`Character "${char}" not found in CHARACTER_SET, skipping`);
        continue;
      }

      if (!valueToIndices[value]) {
        valueToIndices[value] = [];
      }
      valueToIndices[value].push(index);
    }

    // For each value, find consecutive ranges
    const compressed = {};

    for (const [value, indices] of Object.entries(valueToIndices)) {
      // Sort indices
      indices.sort((a, b) => a - b);

      // Find consecutive ranges
      const ranges = this.#findConsecutiveRanges(indices);

      // Convert ranges to notation
      for (const range of ranges) {
        if (range.start === 0 && range.end === CHARACTER_SET.length - 1) {
          // Special case: Full character set
          const firstChar = CHARACTER_SET[0];
          const lastChar = CHARACTER_SET[CHARACTER_SET.length - 1];
          compressed[`${firstChar}-${lastChar}`] = parseFloat(value);
        } else if (range.start === range.end) {
          // Single character
          compressed[CHARACTER_SET[range.start]] = parseFloat(value);
        } else if (range.end === range.start + 1) {
          // Two characters - more efficient as separate entries
          compressed[CHARACTER_SET[range.start]] = parseFloat(value);
          compressed[CHARACTER_SET[range.end]] = parseFloat(value);
        } else {
          // Range of 3+ characters
          const startChar = CHARACTER_SET[range.start];
          const endChar = CHARACTER_SET[range.end];
          compressed[`${startChar}-${endChar}`] = parseFloat(value);
        }
      }
    }

    return compressed;
  }

  /**
   * Finds consecutive ranges in sorted array of indices
   * @param {number[]} indices - Sorted array of indices
   * @returns {Array<{start: number, end: number}>} Array of range objects
   * @private
   */
  static #findConsecutiveRanges(indices) {
    if (indices.length === 0) return [];

    const ranges = [];
    let rangeStart = indices[0];
    let rangeEnd = indices[0];

    for (let i = 1; i < indices.length; i++) {
      if (indices[i] === rangeEnd + 1) {
        // Consecutive, extend range
        rangeEnd = indices[i];
      } else {
        // Gap found, save current range and start new one
        ranges.push({ start: rangeStart, end: rangeEnd });
        rangeStart = indices[i];
        rangeEnd = indices[i];
      }
    }

    // Save final range
    ranges.push({ start: rangeStart, end: rangeEnd });

    return ranges;
  }

  /**
   * Compresses left side of kerning table (characters that come before)
   * TIER 3 OPTIMIZATION: Two-dimensional compression pass 2
   * Groups left characters with identical right-side objects and compresses to ranges
   * Always uses CHARACTER_SET for range compression
   * Example: {"A":{"s":20},"B":{"s":20},"C":{"s":20}} ‚Üí {"A-C":{"s":20}}
   * @param {Object} kerningTable - Right-compressed kerning table
   * @returns {Object} Left-compressed kerning table
   * @private
   */
  static #compressLeftSide(kerningTable) {
    // Group left characters by their right-side object signature
    const rightSideToLeftChars = {};

    for (const [leftChar, rightSideObj] of Object.entries(kerningTable)) {
      const signature = JSON.stringify(rightSideObj);
      if (!rightSideToLeftChars[signature]) {
        rightSideToLeftChars[signature] = [];
      }
      rightSideToLeftChars[signature].push(leftChar);
    }

    // For each group, find consecutive ranges and compress
    const compressed = {};

    for (const [signature, leftChars] of Object.entries(rightSideToLeftChars)) {
      const rightSideObj = JSON.parse(signature);

      // Convert left characters to indices in CHARACTER_SET
      const indices = leftChars
        .map(char => CHARACTER_SET.indexOf(char))
        .filter(idx => idx !== -1)
        .sort((a, b) => a - b);

      // Find consecutive ranges using existing helper
      const ranges = this.#findConsecutiveRanges(indices);

      // Convert ranges to notation (3+ chars ‚Üí range, 1-2 chars ‚Üí keep separate)
      for (const range of ranges) {
        if (range.start === range.end) {
          // Single character
          compressed[CHARACTER_SET[range.start]] = rightSideObj;
        } else if (range.end === range.start + 1) {
          // Two characters - more efficient as separate entries
          compressed[CHARACTER_SET[range.start]] = rightSideObj;
          compressed[CHARACTER_SET[range.end]] = rightSideObj;
        } else {
          // Range of 3+ characters
          const startChar = CHARACTER_SET[range.start];
          const endChar = CHARACTER_SET[range.end];
          compressed[`${startChar}-${endChar}`] = rightSideObj;
        }
      }
    }

    return compressed;
  }

}
// ============================================================================
// METRICS EXPANDER
// Used by MetricsMinifier.minifyWithVerification() for roundtrip checks
// ============================================================================

// Static utility class for expanding minified font metrics data (runtime only)
// Converts compact format back to FontMetrics instances for use by the rendering engine
// NOTE: Requires src/runtime/CHARACTER_SET.js to be loaded first

class MetricsExpander {
  // Private constructor - prevent instantiation following Effective Java patterns
  constructor() {
    throw new Error('MetricsExpander cannot be instantiated - use static methods');
  }
  
  /**
   * Expands minified metrics back to FontMetrics instance for runtime use
   * TIER 2 OPTIMIZATION: Array-based glyph reconstruction
   * TIER 3 OPTIMIZATION: Two-dimensional kerning range expansion
   * TIER 4 OPTIMIZATION: Value indexing (looks up actual values from indices)
   * TIER 5 OPTIMIZATION: Tuplet deduplication (looks up tuplets from indices)
   *
   * REQUIRES: Minified data must NOT contain 'c' field (always uses CHARACTER_SET)
   * REQUIRES: Minified data must contain 'kv' field (kerning value lookup table)
   * REQUIRES: Minified data must contain 'v' field (glyph value lookup table)
   * REQUIRES: Minified data must contain 't' field (tuplet lookup table)
   *
   * @param {Object} minified - Minified metrics object with 'kv', 'k', 'b', 'v', 't', 'g', 's'
   * @returns {FontMetrics} FontMetrics instance with expanded data
   * @throws {Error} If 'c', 'kv', 'v', or 't' fields are missing/invalid
   */
  static expand(minified) {
    // Check if FontMetrics class is available (for cases where loaded as standalone)
    if (typeof FontMetrics === 'undefined') {
      throw new Error('FontMetrics class not found. Please ensure FontMetrics.js is loaded before MetricsExpander.js');
    }

    // Reject legacy format with 'c' field
    if (minified.c) {
      throw new Error(
        `Legacy minified format detected - 'c' field present.\n` +
        `This file was generated with an old character order and is no longer supported.\n` +
        `Please regenerate font assets using the current font-assets-builder.`
      );
    }

    // Require value lookup tables (Tier 4 optimization)
    if (!minified.v) {
      throw new Error(
        `Missing glyph value lookup table ('v' field).\n` +
        `This file was generated with an old format and is no longer supported.\n` +
        `Please regenerate font assets using the current font-assets-builder.`
      );
    }

    if (!minified.kv) {
      throw new Error(
        `Missing kerning value lookup table ('kv' field).\n` +
        `This file was generated with an old format and is no longer supported.\n` +
        `Please regenerate font assets using the current font-assets-builder.`
      );
    }

    // Require tuplet lookup table (Tier 5 optimization)
    if (!minified.t) {
      throw new Error(
        `Missing tuplet lookup table ('t' field).\n` +
        `This file was generated with an old format (Tier 4 only).\n` +
        `Please regenerate font assets using the current font-assets-builder.`
      );
    }

    const expandedData = {
      kerningTable: this.#expandKerningTable(minified.k, minified.kv),
      characterMetrics: this.#expandCharacterMetrics(minified.g, minified.b, minified.v, minified.t),
      spaceAdvancementOverrideForSmallSizesInPx: minified.s
    };

    // Verify pixelDensity was preserved
    const firstChar = Object.keys(expandedData.characterMetrics)[0];
    const pixelDensity = expandedData.characterMetrics[firstChar]?.pixelDensity;
    console.debug(`üîç MetricsExpander: Restored pixelDensity=${pixelDensity} for ${Object.keys(expandedData.characterMetrics).length} characters`);

    return new FontMetrics(expandedData);
  }
  
  /**
   * Expands kerning table with range notation support
   * TIER 3 OPTIMIZATION: Two-dimensional expansion (reverse order of compression)
   * TIER 4 OPTIMIZATION: Value indexing (looks up actual kerning values from indices)
   *   Pass 1 (left-side):  {"A-B":{"s":0}} ‚Üí {"A":{"s":0},"B":{"s":0}}
   *   Pass 2 (right-side): {"A":{"0-1":0}} ‚Üí {"A":{"0":0,"1":0}}
   *   Pass 3 (values):     {"A":{"s":0}} ‚Üí {"A":{"s":20}} (lookup from kerningValueLookup[0])
   * Always uses CHARACTER_SET for range expansion
   * Later entries override earlier ones, allowing exceptions to ranges
   * @param {Object} minified - Minified kerning table with indexed values
   * @param {Array} kerningValueLookup - Value lookup table for kerning values
   * @private
   */
  static #expandKerningTable(minified, kerningValueLookup) {
    // PASS 1: Expand left side (characters that come before)
    const leftExpanded = this.#expandLeftSide(minified);

    // PASS 2: Expand right side (characters that follow)
    const rangeExpanded = {};
    for (const [leftChar, pairs] of Object.entries(leftExpanded)) {
      rangeExpanded[leftChar] = this.#expandKerningPairs(pairs);
    }

    // PASS 3 (TIER 4): Replace all indices with actual values from lookup table
    const expanded = {};
    for (const [leftChar, pairs] of Object.entries(rangeExpanded)) {
      expanded[leftChar] = {};
      for (const [rightChar, index] of Object.entries(pairs)) {
        expanded[leftChar][rightChar] = kerningValueLookup[index];
      }
    }

    return expanded;
  }

  /**
   * Expands left side of kerning table (characters that come before)
   * TIER 3 OPTIMIZATION: Two-dimensional expansion pass 1
   * Handles left-side range notation like "A-C":{"s":20} ‚Üí {"A":{"s":20},"B":{"s":20},"C":{"s":20}}
   * Always uses CHARACTER_SET for range expansion
   * @param {Object} minified - Minified kerning table with potential left-side ranges
   * @returns {Object} Left-expanded kerning table
   * @private
   */
  static #expandLeftSide(minified) {
    const expanded = {};

    // Process entries in order so later entries can override earlier ones
    for (const [key, rightSideObj] of Object.entries(minified)) {
      if (key.includes('-') && key.length >= 3) {
        // Potential range notation (e.g., "A-Z" or "0-9")
        const hyphenIndex = key.indexOf('-');
        const startChar = key.substring(0, hyphenIndex);
        const endChar = key.substring(hyphenIndex + 1);

        // Check if both start and end are single characters in the character set
        if (startChar.length === 1 && endChar.length === 1) {
          const startIndex = CHARACTER_SET.indexOf(startChar);
          const endIndex = CHARACTER_SET.indexOf(endChar);

          if (startIndex !== -1 && endIndex !== -1 && startIndex <= endIndex) {
            // Valid range, expand it
            for (let i = startIndex; i <= endIndex; i++) {
              expanded[CHARACTER_SET[i]] = rightSideObj;
            }
            continue;
          }
        }
      }

      // Not a range, or invalid range - treat as literal character
      expanded[key] = rightSideObj;
    }

    return expanded;
  }

  /**
   * Expands kerning pairs from range notation to individual character pairs
   * Always uses CHARACTER_SET for range expansion
   * @param {Object} pairs - Compressed pairs like {"0-‚ñà":20} or {"A":10,"B-D":20}
   * @returns {Object} Expanded pairs like {"0":20,"1":20,...,"‚ñà":20}
   * @private
   */
  static #expandKerningPairs(pairs) {
    const expanded = {};

    // Process entries in order so later entries can override earlier ones
    for (const [key, value] of Object.entries(pairs)) {
      if (key.includes('-') && key.length >= 3) {
        // Potential range notation (e.g., "A-Z" or "0-‚ñà")
        const hyphenIndex = key.indexOf('-');
        const startChar = key.substring(0, hyphenIndex);
        const endChar = key.substring(hyphenIndex + 1);

        // Check if both start and end are single characters in the character set
        if (startChar.length === 1 && endChar.length === 1) {
          const startIndex = CHARACTER_SET.indexOf(startChar);
          const endIndex = CHARACTER_SET.indexOf(endChar);

          if (startIndex !== -1 && endIndex !== -1 && startIndex <= endIndex) {
            // Valid range, expand it
            for (let i = startIndex; i <= endIndex; i++) {
              expanded[CHARACTER_SET[i]] = value;
            }
            continue;
          }
        }
      }

      // Not a range, or invalid range - treat as literal character
      expanded[key] = value;
    }

    return expanded;
  }
  
  /**
   * Expands glyph metrics from arrays back to full objects
   * TIER 2 OPTIMIZATION: Reconstructs from array of arrays using CHARACTER_SET
   * TIER 4 OPTIMIZATION: Looks up actual values from indices using valueLookup table
   * TIER 5a OPTIMIZATION: Decompresses variable-length tuplets (3/4/5 elements)
   * TIER 5b OPTIMIZATION: Looks up tuplets from tuplet indices
   *
   * Tuplet decompression (deterministic based on length):
   *   - Length 3: [w, l, a] ‚Üí [w, l, w, a, l]  (w===r AND l===d)
   *   - Length 4: [w, l, a, d] ‚Üí [w, l, w, a, d]  (w===r only)
   *   - Length 5: [w, l, r, a, d] (no decompression)
   *
   * Reconstructs full TextMetrics-compatible objects from compact arrays
   * Always uses CHARACTER_SET for character order
   * @param {Array} tupletIndices - Array of tuplet indices (single integers)
   * @param {Object} metricsCommonToAllCharacters - Common metrics shared across all characters
   * @param {Array} valueLookup - Value lookup table mapping indices to actual values
   * @param {Array} tupletLookup - Tuplet lookup table mapping tuplet indices to index arrays
   * @private
   */
  static #expandCharacterMetrics(tupletIndices, metricsCommonToAllCharacters, valueLookup, tupletLookup) {
    const expanded = {};

    // Convert CHARACTER_SET string to array of characters
    const chars = Array.from(CHARACTER_SET);

    // Reconstruct object by mapping array positions to characters
    chars.forEach((char, index) => {
      // TIER 5b: Look up tuplet from tuplet index
      const tupletIndex = tupletIndices[index];
      const compressed = tupletLookup[tupletIndex];

      let indices;

      // TIER 5: Decompress tuplet based on length
      if (compressed.length === 3) {
        // Case C: [w, l, a] ‚Üí [w, l, w, a, l]
        // Both w===r and l===d
        indices = [
          compressed[0],  // width
          compressed[1],  // left
          compressed[0],  // right = width (pattern 1)
          compressed[2],  // ascent
          compressed[1]   // descent = left (pattern 2)
        ];
      }
      else if (compressed.length === 4) {
        // Case B: [w, l, a, d] ‚Üí [w, l, w, a, d]
        // Only w===r
        indices = [
          compressed[0],  // width
          compressed[1],  // left
          compressed[0],  // right = width (pattern 1)
          compressed[2],  // ascent
          compressed[3]   // descent
        ];
      }
      else if (compressed.length === 5) {
        // Case A: [w, l, r, a, d] - no decompression needed
        indices = compressed;
      }
      else {
        throw new Error(
          `Invalid glyph tuplet length for character "${char}" at index ${index}.\n` +
          `Expected 3, 4, or 5 elements, got ${compressed.length}: [${compressed.join(',')}]\n` +
          `This indicates a corrupted font file. Please regenerate font assets.`
        );
      }

      // TIER 4: Look up actual values from indices
      const width = valueLookup[indices[0]];
      const actualBoundingBoxLeft = valueLookup[indices[1]];
      const actualBoundingBoxRight = valueLookup[indices[2]];
      const actualBoundingBoxAscent = valueLookup[indices[3]];
      const actualBoundingBoxDescent = valueLookup[indices[4]];

      expanded[char] = {
        // Glyph-specific metrics looked up from value table
        width,
        actualBoundingBoxLeft,
        actualBoundingBoxRight,
        actualBoundingBoxAscent,
        actualBoundingBoxDescent,

        // Copy over the metrics common to all characters.
        // This is a bit of a waste of memory, however this object needs to
        // look as much as possible like a TextMetrics object, and this
        // is what it looks like.
        fontBoundingBoxAscent: metricsCommonToAllCharacters.fba,
        fontBoundingBoxDescent: metricsCommonToAllCharacters.fbd,
        emHeightAscent: metricsCommonToAllCharacters.fba,          // Same as fontBoundingBoxAscent
        emHeightDescent: metricsCommonToAllCharacters.fbd,         // Same as fontBoundingBoxDescent
        hangingBaseline: metricsCommonToAllCharacters.hb,
        alphabeticBaseline: metricsCommonToAllCharacters.ab,
        ideographicBaseline: metricsCommonToAllCharacters.ib,
        pixelDensity: metricsCommonToAllCharacters.pd              // pixelDensity (CRITICAL for atlas reconstruction)
      };
    });
    return expanded;
  }
  
}
// ============================================================================
// DEEP EQUAL UTILITY
// Used by verification logic to compare original vs expanded metrics
// ============================================================================

// Method 3: Custom recursive comparison
function deepEqual(obj1, obj2) {
  // Check if both are primitive values
  if (obj1 === obj2) return true;
  
  // Check if either is null or not an object
  if (typeof obj1 !== 'object' || obj1 === null ||
      typeof obj2 !== 'object' || obj2 === null) return false;
  
  // Get keys of both objects
  const keys1 = Object.keys(obj1);
  const keys2 = Object.keys(obj2);
  
  // Check if number of keys is different
  if (keys1.length !== keys2.length) return false;
  
  // Recursively compare all properties
  for (const key of keys1) {
      if (!keys2.includes(key)) return false;
      if (!deepEqual(obj1[key], obj2[key])) return false;
  }
  
  return true;
}
// ============================================================================
// MAIN SCRIPT LOGIC
// ============================================================================

// ============================================================================

function processFullMetricsFiles() {
  const fontAssetsDir = path.join(__dirname, '..', 'font-assets');
  const productionDir = fontAssetsDir; // Production files in same directory

  // Check if font-assets directory exists
  if (!fs.existsSync(fontAssetsDir)) {
    console.error('‚ùå font-assets/ directory not found');
    console.error('   Expected at:', fontAssetsDir);
    process.exit(1);
  }

  // Find all -full.js files
  const files = fs.readdirSync(fontAssetsDir).filter(f => f.endsWith('-full.js'));

  if (files.length === 0) {
    console.log('\n‚ö†Ô∏è  No *-full.js files found in font-assets/');
    console.log('');
    console.log('To generate full metrics files:');
    console.log('  1. Open public/font-assets-builder.html in browser');
    console.log('  2. Configure your font settings');
    console.log('  3. Check "Include non-minified metrics files"');
    console.log('  4. Click "Download font assets"');
    console.log('  5. Extract fontAssets.zip to font-assets/');
    console.log('');
    process.exit(0);
  }

  console.log('\nüî¨ Metrics Minification & Verification');
  console.log('‚ïê'.repeat(60));
  console.log(`Found ${files.length} full metrics file(s) to process`);
  if (options.verifyExact) {
    console.log('üîç Exact verification: ENABLED (comparing with production files)');
  }
  console.log('');

  let successCount = 0;
  let errorCount = 0;
  const results = [];

  for (const filename of files) {
    const fullPath = path.join(fontAssetsDir, filename);

    try {
      // Read file content
      const content = fs.readFileSync(fullPath, 'utf8');

      // Extract metricsData using capture mechanism
      // The -full.js files have format:
      // BitmapText.registerMetrics('idString', {...metricsData...})
      let capturedIdString = null;
      let capturedData = null;

      // Create mock BitmapText object to capture data
      const BitmapText = {
        registerMetrics: function(idString, data) {
          capturedIdString = idString;
          capturedData = data;
        }
      };

      // Evaluate the file to trigger registerMetrics call
      eval(content);

      if (!capturedData) {
        throw new Error('Failed to extract metricsData from file (registerMetrics not called)');
      }

      // Calculate original size
      const originalSize = JSON.stringify(capturedData).length;

      // Run minification with automatic roundtrip verification
      // This calls MetricsMinifier.minifyWithVerification() which:
      // 1. Minifies the data
      // 2. Expands it back using MetricsExpander
      // 3. Compares with original using deep-equal
      // 4. Throws error if mismatch
      // 5. Returns minified data on success
      const minified = MetricsMinifier.minifyWithVerification(capturedData);

      // Calculate minified size
      const minifiedSize = JSON.stringify(minified).length;
      const reduction = ((1 - minifiedSize / originalSize) * 100).toFixed(1);
      const savedBytes = originalSize - minifiedSize;

      // Generate output filename
      // Input:  metrics-density-1-0-Arial-style-normal-weight-normal-size-18-0-full.js
      // Output: metrics-density-1-0-Arial-style-normal-weight-normal-size-18-0-full-minified.js
      const baseFilename = filename.replace('-full.js', '');
      const outputFilename = `${baseFilename}-full-minified.js`;
      const outputPath = path.join(fontAssetsDir, outputFilename);

      // Write minified version with EXACT production wrapper
      // Must match: if(typeof BitmapText!=='undefined'&&BitmapText.registerMetrics){BitmapText.registerMetrics('idString',{...})}
      const jsContent = `if(typeof BitmapText!=='undefined'&&BitmapText.registerMetrics){BitmapText.registerMetrics('${capturedIdString}',${JSON.stringify(minified)})}`;
      fs.writeFileSync(outputPath, jsContent, 'utf8');

      // Optional: Verify exact match with production file
      let exactMatch = null;
      if (options.verifyExact) {
        // Find corresponding production file (without -full suffix)
        const productionFilename = filename.replace('-full.js', '.js');
        const productionPath = path.join(productionDir, productionFilename);

        if (fs.existsSync(productionPath)) {
          const productionContent = fs.readFileSync(productionPath, 'utf8');
          exactMatch = (jsContent === productionContent);
        } else {
          exactMatch = 'no-production-file';
        }
      }

      results.push({
        input: filename,
        output: outputFilename,
        originalSize,
        minifiedSize,
        reduction,
        savedBytes,
        exactMatch,
        status: 'success'
      });

      console.log(`‚úÖ ${filename}`);
      console.log(`   ‚Üí ${outputFilename}`);
      console.log(`   ID: ${capturedIdString}`);
      console.log(`   Original: ${originalSize.toLocaleString()} chars`);
      console.log(`   Minified: ${minifiedSize.toLocaleString()} chars`);
      console.log(`   Saved: ${savedBytes.toLocaleString()} chars (${reduction}% reduction)`);
      console.log(`   ‚úì Roundtrip verification passed`);

      if (options.verifyExact) {
        if (exactMatch === true) {
          console.log(`   ‚úì Exact match with production file`);
        } else if (exactMatch === false) {
          console.log(`   ‚ö†Ô∏è  Output differs from production file`);
        } else if (exactMatch === 'no-production-file') {
          console.log(`   ‚ÑπÔ∏è  No production file to compare (${filename.replace('-full.js', '.js')} not found)`);
        }
      }

      console.log('');

      successCount++;

    } catch (error) {
      results.push({
        input: filename,
        status: 'error',
        error: error.message
      });

      console.error(`‚ùå ${filename}`);
      console.error(`   Error: ${error.message}`);
      if (error.stack) {
        // Show first few lines of stack for debugging
        const stackLines = error.stack.split('\n').slice(0, 3).join('\n');
        console.error(`   Stack: ${stackLines}`);
      }
      console.error('');

      errorCount++;
    }
  }

  // Print summary
  console.log('‚ïê'.repeat(60));
  console.log(`üìä Summary: ${successCount} successful, ${errorCount} error(s)`);
  console.log('‚ïê'.repeat(60));

  if (successCount > 0) {
    console.log('\n‚úÖ Successfully minified files:');
    const successResults = results.filter(r => r.status === 'success');

    // Calculate totals
    let totalOriginal = 0;
    let totalMinified = 0;

    successResults.forEach(r => {
      totalOriginal += r.originalSize;
      totalMinified += r.minifiedSize;
      console.log(`   ${r.output}`);
      console.log(`     ${r.originalSize.toLocaleString()} ‚Üí ${r.minifiedSize.toLocaleString()} chars (${r.reduction}% reduction)`);
    });

    const totalSaved = totalOriginal - totalMinified;
    const totalReduction = ((1 - totalMinified / totalOriginal) * 100).toFixed(1);

    console.log('');
    console.log(`   Total: ${totalOriginal.toLocaleString()} ‚Üí ${totalMinified.toLocaleString()} chars`);
    console.log(`   Saved: ${totalSaved.toLocaleString()} chars (${totalReduction}% overall reduction)`);

    // Report exact match results if verification was enabled
    if (options.verifyExact) {
      const exactMatches = successResults.filter(r => r.exactMatch === true).length;
      const mismatches = successResults.filter(r => r.exactMatch === false).length;
      const noProductionFile = successResults.filter(r => r.exactMatch === 'no-production-file').length;

      console.log('');
      console.log('üîç Exact Verification Results:');
      if (exactMatches > 0) {
        console.log(`   ‚úì ${exactMatches} file(s) match production exactly`);
      }
      if (mismatches > 0) {
        console.log(`   ‚ö†Ô∏è  ${mismatches} file(s) differ from production`);
      }
      if (noProductionFile > 0) {
        console.log(`   ‚ÑπÔ∏è  ${noProductionFile} file(s) have no production file to compare`);
      }
    }
  }

  if (errorCount > 0) {
    console.log('\n‚ùå Errors:');
    results.filter(r => r.status === 'error').forEach(r => {
      console.log(`   ${r.input}: ${r.error}`);
    });
  }

  console.log('\nüí° Output files can be used to test different minification strategies');
  console.log('   by modifying MetricsMinifier.js and rebuilding this tool.');
  console.log('');
  if (!options.verifyExact) {
    console.log('   Tip: Use --verify-exact to compare with production files');
    console.log('   (useful for validating the tool produces identical output).');
    console.log('');
  }

  process.exit(errorCount > 0 ? 1 : 0);
}

// Run main function
processFullMetricsFiles();

