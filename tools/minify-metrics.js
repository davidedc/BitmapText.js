#!/usr/bin/env node

/**
 * ‚ö†Ô∏è  THIS IS A BUNDLED/BUILT FILE - DO NOT EDIT ‚ö†Ô∏è
 *
 * Metrics Minifier - Processes full metrics files and outputs minified versions
 *
 * This file is automatically generated by concatenating multiple source files.
 * It uses the EXACT SAME CODE as the font-assets-builder page for minification
 * and roundtrip verification, ensuring identical behavior.
 *
 * Source files concatenated (in dependency order):
 *   1. src/runtime/CHARACTER_SET.js - Character set constant (204 chars)
 *   2. src/runtime/FontMetrics.js - FontMetrics class
 *   3. src/builder/MetricsMinifier.js - Minification logic
 *   4. src/builder/MetricsExpander.js - Expansion for roundtrip
 *   5. src/utils/deep-equal.js - Deep equality comparison
 *
 * Purpose:
 *   - Find all *-full.js files in font-assets/
 *   - Extract full metricsData from each file
 *   - Run MetricsMinifier.minifyWithVerification() (includes roundtrip check)
 *   - Output minified .js files as *-full-minified.js
 *   - Report statistics and verification results
 *
 * Usage:
 *   ./tools/minify-metrics.js [options]
 *   node tools/minify-metrics.js [options]
 *
 * Options:
 *   --verify-exact    Compare output with production metrics-*.js files (byte-for-byte)
 *   --help, -h        Show this help message
 *
 * Input:  font-assets/metrics-...-full.js (full metrics from font-assets-builder)
 * Output: font-assets/metrics-...-full-minified.js (minified .js files)
 *
 * To rebuild this tool:
 *   ./scripts/build-metrics-minifier.sh
 *
 * Generated by: scripts/build-metrics-minifier.sh
 */

// ============================================================================
// NODE.JS BUILT-IN MODULES
// ============================================================================

const fs = require('fs');
const path = require('path');

// ============================================================================
// COMMAND-LINE ARGUMENT PARSING
// ============================================================================

const args = process.argv.slice(2);
const options = {
  verifyExact: args.includes('--verify-exact'),
  help: args.includes('--help') || args.includes('-h')
};

if (options.help) {
  console.log(`
Metrics Minifier - Test minification strategies on full metrics files

Usage:
  ./tools/minify-metrics.js [options]
  node tools/minify-metrics.js [options]

Options:
  --verify-exact    Compare output with production metrics-*.js files
                    Performs byte-for-byte comparison to verify node script
                    produces identical output to browser font-assets-builder
                    (useful for validating the tool, not for testing new strategies)

  --help, -h        Show this help message

Description:
  Processes all *-full.js files in font-assets/ directory:
  1. Extracts full metricsData from each file
  2. Runs MetricsMinifier.minifyWithVerification() (includes roundtrip check)
  3. Outputs minified .js files as *-full-minified.js
  4. Reports statistics and verification results

  The tool uses the EXACT same minification code as the browser
  font-assets-builder page, ensuring identical behavior.

Prerequisites:
  Generate *-full.js files first:
  1. Open public/font-assets-builder.html in browser
  2. Configure font settings
  3. Check "Include non-minified metrics files"
  4. Click "Download font assets"
  5. Extract fontAssets.zip to font-assets/

Examples:
  # Standard usage (no comparison with production files)
  ./tools/minify-metrics.js

  # Verify output matches production files exactly
  ./tools/minify-metrics.js --verify-exact

Development Workflow:
  # Test new minification strategy
  1. Edit src/builder/MetricsMinifier.js
  2. ./scripts/build-metrics-minifier.sh
  3. ./tools/minify-metrics.js
  4. Examine *-full-minified.js output files
`);
  process.exit(0);
}

// ============================================================================
// CHARACTER SET CONSTANT
// Required by both MetricsMinifier and MetricsExpander
// ============================================================================

// CHARACTER SET CONSTANT - 204 characters
// Used by both build-time (MetricsMinifier) and runtime (MetricsExpander)
//
// This is the sorted character set that defines the standard order for all font metrics.
// ALL font files must contain exactly these 204 characters in this order.

// Generate character set programmatically
function generateCharacterSet() {
  const chars = [];

  // ASCII printable characters (32-126)
  // Includes space, numbers, letters, and common symbols
  for (let i = 32; i <= 126; i++) {
    chars.push(String.fromCharCode(i));
  }

  // A selection from Windows-1252 (CP-1252) printable characters.
  // This is the most standard definition of "extended ASCII codes" from 128 to 159
  // and many of these are common/useful symbols that people "expect to have".
  // However fromCharCode doesn't work on those as that range is not defined
  // in UTF-8/Unicode (modern web standard, so we want to include (some of) them but we have
  // to map them to specific Unicode code points, not the byte values themselves.
  // NOTE: we could likely shave some of these off, as they are not easily printable
  // in Javascript and some of them are fairly arcane/
  const cp1252PrintableChars = [
    8364, // ‚Ç¨ Euro sign (CP-1252: 128)
    //  8218, // ‚Äö Single low-9 quotation mark (CP-1252: 130)
    //  402,  // ∆í Latin small letter f with hook (CP-1252: 131)
    //  8222, // ‚Äû Double low-9 quotation mark (CP-1252: 132)
    8230, // ‚Ä¶ Horizontal ellipsis (CP-1252: 133)
    //  8224, // ‚Ä† Dagger (CP-1252: 134)
    //  8225, // ‚Ä° Double dagger (CP-1252: 135)
    //  710,  // ÀÜ Modifier letter circumflex accent (CP-1252: 136)
    8240, // ‚Ä∞ Per mille sign (CP-1252: 137)
    //  352,  // ≈† Latin capital letter S with caron (CP-1252: 138)
    8249, // ‚Äπ Single left-pointing angle quotation (CP-1252: 139)
    //  338,  // ≈í Latin capital ligature OE (CP-1252: 140)
    381,  // ≈Ω Latin capital letter Z with caron (CP-1252: 142)
    //  8216, // ' Left single quotation mark (CP-1252: 145)

    // UNFORTUNATELY SOMETIMES USED INSTEAD OF APOSTROPHE
    8217, // ' ""curly apostrophe"" or "right single quotation mark" (CP-1252: 146)

    //  8220, // " Left double quotation mark (CP-1252: 147)
    //  8221, // " Right double quotation mark (CP-1252: 148)
    8226, // ‚Ä¢ Bullet (CP-1252: 149)
    //  8211, // ‚Äì En dash (CP-1252: 150)
    8212, // ‚Äî Em dash (CP-1252: 151)
    //  732,  // Àú Small tilde (CP-1252: 152)
    8482, // ‚Ñ¢ Trade mark sign (CP-1252: 153)
    353,  // ≈° Latin small letter S with caron (CP-1252: 154)
    8250, // ‚Ä∫ Single right-pointing angle quotation mark (CP-1252: 155)
    339,  // ≈ì Latin small ligature oe (CP-1252: 156)
    382,  // ≈æ Latin small letter z with caron (CP-1252: 158)
    376   // ≈∏ Latin capital letter Y with diaeresis (CP-1252: 159)
  ];

  for (const code of cp1252PrintableChars) {
    chars.push(String.fromCharCode(code));
  }

  // Latin-1 Supplement characters (161-255)
  // These are properly defined in UTF-8/Unicode
  // Exclude U+00AD (173) - soft hyphen, which has zero width
  for (let i = 161; i <= 255; i++) {
    if (i !== 173) { // Skip soft hyphen
      chars.push(String.fromCharCode(i));
    }
  }

  // Add Full Block character (allows us to see the maximum space taken by a glyph)
  chars.push('‚ñà');

  // Sort the character set (this is how it's used throughout the codebase)
  return chars.sort().join('');
}

// Export as constant
const CHARACTER_SET = generateCharacterSet();

// ============================================================================
// FONT METRICS CLASS
// Required by MetricsExpander for creating FontMetrics instances
// ============================================================================

// FontMetrics - Core Runtime Class
//
// This is a CORE RUNTIME class designed for minimal bundle size (~3-4KB).
// It encapsulates all metrics data for a single font configuration as an immutable domain object.
//
// DISTRIBUTION ROLE:
// - Part of "runtime-only" distribution for production applications
// - Extended by FontMetricsFAB for font assets building capabilities
// - Contains only essential metrics data and accessor methods
// - No font generation, validation, or optimization code
//
// ARCHITECTURE:
// - Immutable object representing all metrics for ONE font configuration
// - Pre-computed lookups for optimal performance during text rendering
// - Provides clean API without needing fontProperties passed to every method
// - Follows same immutable pattern as FontProperties
//
// SEPARATION RATIONALE:
// - Encapsulates related metrics data together
// - Eliminates repeated fontProperties parameter passing
// - Serves as domain object for font metrics
// - Enables cleaner, more object-oriented API
//
// For font assets building capabilities, use FontMetricsFAB which extends this class.
class FontMetrics {
  constructor(data, options = {}) {
    // Validate input data structure
    if (!data || typeof data !== 'object') {
      throw new Error('FontMetrics constructor requires data object');
    }
    
    // Kerning table: character pairs ‚Üí adjustment values
    this._kerningTable = data.kerningTable || {};
    
    // Character metrics: character ‚Üí TextMetrics-compatible object
    this._characterMetrics = data.characterMetrics || {};
    
    // Space advancement override for small font sizes
    this._spaceAdvancementOverride = data.spaceAdvancementOverrideForSmallSizesInPx || null;
    
    // Freeze for immutability (safe to use as value object)
    // Skip freezing if this is for font assets building (FAB)
    if (!options.mutable) {
      Object.freeze(this._kerningTable);
      Object.freeze(this._characterMetrics);
      Object.freeze(this);
    }
  }
  
  /**
   * Get text measurement metrics for a character
   * @param {string} char - Character (code point) to get metrics for
   * @returns {Object} TextMetrics-compatible object
   */
  getCharacterMetrics(char) {
    return this._characterMetrics[char];
  }
  
  /**
   * Get kerning adjustment between two characters
   * @param {string} leftChar - Left character in pair
   * @param {string} rightChar - Right character in pair  
   * @returns {number} Kerning adjustment value (0 if no adjustment)
   */
  getKerningAdjustment(leftChar, rightChar) {
    if (!leftChar || !rightChar) return 0;
    return this._kerningTable[leftChar]?.[rightChar] || 0;
  }
  
  /**
   * Check if glyph exists in this font
   * @param {string} char - Character (code point) to check
   * @returns {boolean} True if glyph has metrics
   */
  hasGlyph(char) {
    return char in this._characterMetrics;
  }
  
  /**
   * Get space advancement override for small font sizes
   * @returns {number|null} Override value in pixels, or null if no override
   */
  getSpaceAdvancementOverride() {
    return this._spaceAdvancementOverride;
  }
  
  /**
   * Get the complete kerning table (for compatibility/debugging)
   * @returns {Object} Complete kerning table
   */
  getKerningTable() {
    return this._kerningTable;
  }
  
  /**
   * Get all available characters in this font
   * @returns {string[]} Array of available characters
   */
  getAvailableCharacters() {
    return Object.keys(this._characterMetrics);
  }
  
}
// ============================================================================
// METRICS MINIFIER
// Tier 3-5 optimizations: 2D kerning, value indexing, tuplet deduplication
// ============================================================================

// Static utility class for minifying font metrics data (build-time only)
// Converts verbose object structures to compact format for smaller file sizes
// NOTE: Requires src/runtime/CHARACTER_SET.js to be loaded first

class MetricsMinifier {
  // Private constructor - prevent instantiation following Effective Java patterns
  constructor() {
    throw new Error('MetricsMinifier cannot be instantiated - use static methods');
  }
  
  /**
   * Compresses font ID string from verbose format to compact format
   * TIER 6 OPTIMIZATION: Font ID compression
   *
   * @param {string} idString - Full ID like 'density-1-0-Arial-style-normal-weight-normal-size-18-0'
   * @returns {string} Compact ID like '1,Arial,0,0,18'
   */
  static compressFontID(idString) {
    // Parse: density-1-0-Arial-style-normal-weight-normal-size-18-0
    const parts = idString.split('-');

    // Extract values
    const density = parts[1] + (parts[2] === '0' ? '' : '.' + parts[2]); // "1" or "1.5"
    const fontFamily = parts[3];
    const style = parts[5]; // "normal", "italic", "oblique"
    const weight = parts[7]; // "normal", "bold", or numeric
    const size = parts[9] + (parts[10] === '0' ? '' : '.' + parts[10]); // "18" or "18.5"

    // Compress style: 0=normal, 1=italic, 2=oblique
    const styleIdx = style === 'normal' ? '0' : (style === 'italic' ? '1' : '2');

    // Compress weight: 0=normal, 1=bold, or keep numeric
    const weightIdx = weight === 'normal' ? '0' : (weight === 'bold' ? '1' : weight);

    // Format: density,fontFamily,styleIdx,weightIdx,size
    return `${density},${fontFamily},${styleIdx},${weightIdx},${size}`;
  }

  /**
   * Decompresses font ID string from compact format to verbose format
   * TIER 6 OPTIMIZATION: Font ID decompression
   *
   * @param {string} compressed - Compact ID like '1,Arial,0,0,18'
   * @returns {string} Full ID like 'density-1-0-Arial-style-normal-weight-normal-size-18-0'
   */
  static decompressFontID(compressed) {
    const parts = compressed.split(',');

    // Parse compact format: density,fontFamily,styleIdx,weightIdx,size
    const density = parts[0];
    const fontFamily = parts[1];
    const styleIdx = parts[2];
    const weightIdx = parts[3];
    const size = parts[4];

    // Decompress style
    const style = styleIdx === '0' ? 'normal' : (styleIdx === '1' ? 'italic' : 'oblique');

    // Decompress weight
    const weight = weightIdx === '0' ? 'normal' : (weightIdx === '1' ? 'bold' : weightIdx);

    // Format density (1 ‚Üí 1-0, 1.5 ‚Üí 1-5)
    const densityFormatted = density.includes('.') ? density.replace('.', '-') : `${density}-0`;

    // Format size (18 ‚Üí 18-0, 18.5 ‚Üí 18-5)
    const sizeFormatted = size.includes('.') ? size.replace('.', '-') : `${size}-0`;

    // Reconstruct full ID
    return `density-${densityFormatted}-${fontFamily}-style-${style}-weight-${weight}-size-${sizeFormatted}`;
  }

  /**
   * TIER 6c OPTIMIZATION: Encode array of integers to base64 byte array
   * Each integer (0-255) becomes one byte
   *
   * @param {Array<number>} integers - Array of integers (0-255)
   * @returns {string} Base64 encoded string
   */
  static #encodeToBase64Bytes(integers) {
    // In browser: use btoa
    // In Node.js: use Buffer
    const bytes = new Uint8Array(integers);

    if (typeof Buffer !== 'undefined') {
      // Node.js environment
      return Buffer.from(bytes).toString('base64');
    } else {
      // Browser environment
      const binary = String.fromCharCode.apply(null, bytes);
      return btoa(binary);
    }
  }

  /**
   * TIER 6c OPTIMIZATION: Encode signed integers using zigzag + varint + base64
   * Zigzag: 0‚Üí0, -1‚Üí1, 1‚Üí2, -2‚Üí3, 2‚Üí4, ...
   * VarInt: 0-127 use 1 byte, 128+ use 2+ bytes
   *
   * @param {Array<number>} signedIntegers - Array of signed integers
   * @returns {string} Base64 encoded varint bytes
   */
  static #encodeVarInts(signedIntegers) {
    const bytes = [];

    for (const value of signedIntegers) {
      // Zigzag encoding: convert signed to unsigned
      // n >= 0 ‚Üí 2n
      // n < 0 ‚Üí -2n - 1
      const zigzagged = value >= 0 ? (value * 2) : (-value * 2 - 1);

      // VarInt encoding: 7 bits per byte, MSB indicates continuation
      let remaining = zigzagged;
      while (remaining >= 128) {
        bytes.push((remaining & 0x7F) | 0x80); // Set continuation bit
        remaining >>>= 7;
      }
      bytes.push(remaining & 0x7F); // Last byte, no continuation bit
    }

    return this.#encodeToBase64Bytes(bytes);
  }

  /**
   * TIER 7 OPTIMIZATION: Compress value lookup array using delta encoding + base64
   *
   * Strategy:
   * 1. Values are already magnitude-sorted (from #createValueLookupTable)
   * 2. Convert to deltas (first value + differences)
   * 3. Encode using zigzag + varint + base64
   *
   * Example: [0, 100107, 120059] ‚Üí deltas: [0, 100107, 19952] ‚Üí base64
   *
   * @param {Array<number>} valueIntegers - Magnitude-sorted array of metric value integers
   * @returns {string} Base64 encoded delta-compressed string
   */
  static #compressValueArray(valueIntegers) {
    // Values are already magnitude-sorted from #createValueLookupTable (TIER 7)
    // No need to sort again - preserves ordering and avoids redundant work

    // Convert to deltas
    const deltas = [valueIntegers[0]]; // First value stays as-is
    for (let i = 1; i < valueIntegers.length; i++) {
      deltas.push(valueIntegers[i] - valueIntegers[i - 1]);
    }

    // Encode using existing varint infrastructure
    return this.#encodeVarInts(deltas);
  }

  /**
   * Minifies font metrics data for smaller file size
   * TIER 2 OPTIMIZATION: Array-based glyph encoding
   * TIER 3 OPTIMIZATION: Two-dimensional kerning range compression
   * TIER 4 OPTIMIZATION: Value indexing (replaces repeated metric values with indices)
   * TIER 5 OPTIMIZATION: Tuplet deduplication (deduplicates glyph index arrays)
   * TIER 6 OPTIMIZATION: Additional space optimizations (baseline/top-level arrays, tuplet flattening, integer values)
   * TIER 6c OPTIMIZATION: Binary encoding for tuplet indices and flattened tuplets
   * TIER 7 OPTIMIZATION: Delta encoding + base64 for value lookup array
   *
   * REQUIRES: metricsData.characterMetrics must contain ALL 204 characters from CHARACTER_SET
   *
   * @param {Object} metricsData - Full metrics object containing kerningTable, characterMetrics, etc.
   * @returns {Array} Minified metrics as array (Tier 7: element [3] is now base64 string)
   * @throws {Error} If not all 204 characters are present
   */
  static minify(metricsData) {
    // Validate that ALL 204 characters from CHARACTER_SET are present
    // Note: We DON'T use Object.keys() because JavaScript reorders numeric keys
    // Instead, we iterate through CHARACTER_SET and check each character exists
    const missingChars = [];
    for (const char of CHARACTER_SET) {
      if (!(char in metricsData.characterMetrics)) {
        missingChars.push(char);
      }
    }

    if (missingChars.length > 0) {
      throw new Error(
        `MetricsMinifier requires ALL 204 characters from CHARACTER_SET.\n` +
        `Missing ${missingChars.length} characters: ${missingChars.slice(0, 10).join(', ')}${missingChars.length > 10 ? '...' : ''}\n` +
        `Please ensure font-assets-builder generates ALL 204 characters.`
      );
    }

    // Check for extra characters not in CHARACTER_SET
    const extraChars = Object.keys(metricsData.characterMetrics).filter(
      char => !CHARACTER_SET.includes(char)
    );

    if (extraChars.length > 0) {
      throw new Error(
        `Font contains ${extraChars.length} characters not in CHARACTER_SET: ${extraChars.join(', ')}\n` +
        `Please update src/runtime/CHARACTER_SET.js to include these characters.`
      );
    }

    // TIER 6b: Find most common left bounding box value for 2-element tuplet compression
    const commonLeftValue = this.#findCommonLeftValue(metricsData.characterMetrics);

    // TIER 4+6b: Create value lookup table and indexed glyph arrays with 2-element compression
    const { valueLookup, indexedGlyphs, commonLeftIndex } = this.#createValueLookupTable(
      metricsData.characterMetrics,
      commonLeftValue
    );

    // TIER 4: Create kerning value lookup table and indexed kerning table
    const { kerningValueLookup, indexedKerningTable } = this.#createKerningValueLookupTable(
      metricsData.kerningTable
    );

    // TIER 5: Create tuplet lookup table and tuplet indices
    const { tupletLookup, tupletIndices } = this.#createTupletLookupTable(
      indexedGlyphs
    );

    // TIER 6a: Convert value lookups to integers (multiply by 10000)
    const valueLookupIntegers = this.#convertValuesToIntegers(valueLookup);
    const kerningValueLookupIntegers = this.#convertValuesToIntegers(kerningValueLookup);

    // TIER 6: Flatten baseline object to array
    const baselineArray = this.#flattenBaseline(
      this.#extractMetricsCommonToAllCharacters(metricsData.characterMetrics)
    );

    // TIER 6: Flatten tuplet lookup arrays to negative-delimiter format
    const flattenedTuplets = this.#flattenTuplets(tupletLookup);

    // TIER 6c: Encode tuplet indices as base64 byte array (A1 optimization)
    // Each index 0-255 becomes one byte, then base64 encode
    // Savings: ~320 bytes (593 bytes JSON ‚Üí ~270 bytes base64)
    const encodedTupletIndices = this.#encodeToBase64Bytes(tupletIndices);

    // TIER 6c: Encode flattened tuplets as varint+base64 (A2 optimization)
    // Zigzag encoding handles negative delimiters, varint compresses small values
    // Savings: ~500 bytes (1209 bytes JSON ‚Üí ~700 bytes base64)
    const encodedFlattenedTuplets = this.#encodeVarInts(flattenedTuplets);

    // TIER 7: Compress value lookup array using delta encoding + base64
    // Savings: ~380 bytes (664 bytes JSON ‚Üí ~280 bytes base64)
    const encodedValueLookup = this.#compressValueArray(valueLookupIntegers);

    // TIER 7: Return as array with encoded binary data
    // Array format: [kv, k, b, v, t, g, s, cl]
    // NOTE: Elements 3, 4, and 5 are now base64 strings instead of arrays
    return [
      kerningValueLookupIntegers,  // 0: TIER 4+6: Kerning value lookup (as integers)
      indexedKerningTable,         // 1: TIER 4: Kerning table with indexed values
      baselineArray,               // 2: TIER 6: Baseline array [fba,fbd,hb,ab,ib,pd]
      encodedValueLookup,          // 3: TIER 7: Delta+VarInt encoded glyph value lookup (base64 string)
      encodedFlattenedTuplets,     // 4: TIER 6c: VarInt encoded flattened tuplets (base64 string)
      encodedTupletIndices,        // 5: TIER 6c: Byte-encoded tuplet indices (base64 string)
      metricsData.spaceAdvancementOverrideForSmallSizesInPx,  // 6: Space override
      commonLeftIndex              // 7: TIER 6b: Common left index for 2-element tuplet decompression
    ];
  }

  /**
   * Minifies font metrics data with automatic roundtrip verification
   * This is the RECOMMENDED method for font-assets-builder to catch compression bugs immediately
   *
   * Process:
   * 1. Minify the metrics data
   * 2. Expand it back using MetricsExpander
   * 3. Compare expanded data with original
   * 4. Throw detailed error if mismatch (prevents broken font files)
   * 5. Return minified data if verification passes
   *
   * @param {Object} metricsData - Full metrics object containing kerningTable, characterMetrics, etc.
   * @returns {Object} Minified metrics with verified integrity
   * @throws {Error} If roundtrip verification fails
   */
  static minifyWithVerification(metricsData) {
    // Step 1: Minify
    const minified = this.minify(metricsData);

    // Step 2: Check if MetricsExpander is available
    if (typeof MetricsExpander === 'undefined') {
      console.warn('‚ö†Ô∏è  MetricsExpander not loaded - skipping roundtrip verification');
      return minified;
    }

    // Step 3: Expand back
    const expanded = MetricsExpander.expand(minified);

    // Step 4: Verify kerning table
    const originalKerning = metricsData.kerningTable;
    const expandedKerning = expanded._kerningTable;

    // Check all original kerning pairs
    for (const [leftChar, pairs] of Object.entries(originalKerning)) {
      if (!expandedKerning[leftChar]) {
        throw new Error(
          `Roundtrip verification failed: Missing left character "${leftChar}" in expanded kerning table.\n` +
          `This indicates a bug in MetricsMinifier compression or MetricsExpander expansion.`
        );
      }

      for (const [rightChar, value] of Object.entries(pairs)) {
        const expandedValue = expandedKerning[leftChar][rightChar];
        if (expandedValue !== value) {
          throw new Error(
            `Roundtrip verification failed: Kerning mismatch for "${leftChar}/${rightChar}".\n` +
            `Expected: ${value}, Got: ${expandedValue}\n` +
            `This indicates a bug in MetricsMinifier compression or MetricsExpander expansion.`
          );
        }
      }
    }

    // Check for extra kerning pairs in expanded (should not happen)
    for (const [leftChar, pairs] of Object.entries(expandedKerning)) {
      if (!originalKerning[leftChar]) {
        throw new Error(
          `Roundtrip verification failed: Extra left character "${leftChar}" in expanded kerning table.\n` +
          `This indicates a bug in MetricsExpander expansion.`
        );
      }

      for (const rightChar of Object.keys(pairs)) {
        if (!(rightChar in originalKerning[leftChar])) {
          throw new Error(
            `Roundtrip verification failed: Extra kerning pair "${leftChar}/${rightChar}" in expanded data.\n` +
            `This indicates a bug in MetricsExpander expansion.`
          );
        }
      }
    }

    // Step 5: Verify character metrics count
    const originalCharCount = Object.keys(metricsData.characterMetrics).length;
    const expandedCharCount = Object.keys(expanded._characterMetrics).length;

    if (originalCharCount !== expandedCharCount) {
      throw new Error(
        `Roundtrip verification failed: Character count mismatch.\n` +
        `Expected: ${originalCharCount}, Got: ${expandedCharCount}\n` +
        `This indicates a bug in MetricsMinifier or MetricsExpander.`
      );
    }

    // All checks passed!
    console.debug('‚úÖ Roundtrip verification passed - compression integrity verified');
    return minified;
  }

  /**
   * Extracts common metrics shared across all characters
   * so that we don't need to repeat these in the serialised file.
   * Extract these from the first character in CHARACTER_SET (space)
   * @private
   */
  static #extractMetricsCommonToAllCharacters(characterMetrics) {
    // Use first character from CHARACTER_SET (space character)
    const firstChar = CHARACTER_SET[0];
    const firstGlyph = characterMetrics[firstChar];

    return {
      fba: firstGlyph.fontBoundingBoxAscent,     // fontBoundingBoxAscent
      fbd: firstGlyph.fontBoundingBoxDescent,    // fontBoundingBoxDescent
      hb: firstGlyph.hangingBaseline,            // hangingBaseline
      ab: firstGlyph.alphabeticBaseline,         // alphabeticBaseline
      ib: firstGlyph.ideographicBaseline,        // ideographicBaseline
      pd: firstGlyph.pixelDensity                // pixelDensity (CRITICAL for atlas reconstruction)
    };
  }
  
  /**
   * Finds the most common left bounding box value across all glyphs
   * TIER 6b OPTIMIZATION: 2-element tuplet compression requires common left value
   *
   * Analysis shows ~92% of glyphs share the same left value (usually 0)
   * This enables aggressive 2-element tuplet compression for these glyphs
   *
   * @param {Object} characterMetrics - Character metrics object with all 204 characters
   * @returns {number} Most common left bounding box value
   * @private
   */
  static #findCommonLeftValue(characterMetrics) {
    // Count frequency of each left value
    const leftValueCounts = new Map();

    for (const char of CHARACTER_SET) {
      const leftValue = characterMetrics[char].actualBoundingBoxLeft;
      leftValueCounts.set(leftValue, (leftValueCounts.get(leftValue) || 0) + 1);
    }

    // Find the most frequent left value
    let mostCommonValue = 0;
    let maxCount = 0;

    for (const [value, count] of leftValueCounts.entries()) {
      if (count > maxCount) {
        maxCount = count;
        mostCommonValue = value;
      }
    }

    console.debug(`üîç Common left value: ${mostCommonValue} (appears in ${maxCount}/${CHARACTER_SET.length} glyphs, ${(maxCount/CHARACTER_SET.length*100).toFixed(1)}%)`);

    return mostCommonValue;
  }

  /**
   * Creates value lookup table and converts glyph metrics to indexed arrays with tuplet compression
   * TIER 4 OPTIMIZATION: Value indexing - replaces repeated metric values with indices
   * TIER 5 OPTIMIZATION: Tuplet compression - reduces tuplet length from 5 to 3/4/5 based on redundancy
   * TIER 6b OPTIMIZATION: 2-element tuplet compression - further reduces when left===common
   * TIER 7 OPTIMIZATION: Magnitude-sorted value array for optimal delta encoding
   *
   * Strategy: Sort values by magnitude (ascending) for optimal delta encoding compression.
   * This enables small deltas in the base64-encoded value array (~2K avg vs ~80K for unsorted).
   *
   * Tuplet compression (cascading, most-frequent-first):
   *   - Case D (2 elements): w===r AND l===d AND l===CL  ‚Üí  [w, a]  (CL = common left)
   *   - Case C (3 elements): w===r AND l===d             ‚Üí  [w, l, a]
   *   - Case B (4 elements): w===r only                  ‚Üí  [w, l, a, d]
   *   - Case A (5 elements): no compression              ‚Üí  [w, l, r, a, d]
   *
   * @param {Object} characterMetrics - Character metrics object with all 204 characters
   * @param {number} commonLeftValue - Most common left bounding box value (will be converted to index)
   * @returns {Object} Object with valueLookup array, indexedGlyphs array, and commonLeftIndex
   * @private
   */
  static #createValueLookupTable(characterMetrics, commonLeftValue) {
    // Step 1: Collect all unique values
    const uniqueValues = new Set();

    for (const char of CHARACTER_SET) {
      const glyph = characterMetrics[char];
      uniqueValues.add(glyph.width);
      uniqueValues.add(glyph.actualBoundingBoxLeft);
      uniqueValues.add(glyph.actualBoundingBoxRight);
      uniqueValues.add(glyph.actualBoundingBoxAscent);
      uniqueValues.add(glyph.actualBoundingBoxDescent);
    }

    // Step 2: Sort by magnitude (ascending) for optimal delta encoding
    // TIER 7: Magnitude sorting enables efficient delta compression
    // Sorted sequence (e.g., 0, 156, 1563...) has small deltas (~2K avg)
    // vs unsorted (e.g., 100107, 0, 120059...) has huge deltas (~80K avg)
    const valueLookup = Array.from(uniqueValues).sort((a, b) => a - b);

    // Step 3: Create value-to-index map for fast lookup during indexing
    const valueToIndex = new Map();
    valueLookup.forEach((value, index) => {
      valueToIndex.set(value, index);
    });

    // TIER 6b: Convert common left value to index for tuplet compression
    const commonLeftIndex = valueToIndex.get(commonLeftValue);
    if (commonLeftIndex === undefined) {
      throw new Error(`Common left value ${commonLeftValue} not found in value lookup table`);
    }
    console.debug(`üîç Common left index after value mapping: ${commonLeftIndex}`);

    // Step 5: Convert glyph arrays to indices and compress tuplets (TIER 5+6b)
    const indexedGlyphs = Array.from(CHARACTER_SET).map(char => {
      const glyph = characterMetrics[char];
      const indices = [
        valueToIndex.get(glyph.width),                      // 0: width
        valueToIndex.get(glyph.actualBoundingBoxLeft),      // 1: left
        valueToIndex.get(glyph.actualBoundingBoxRight),     // 2: right
        valueToIndex.get(glyph.actualBoundingBoxAscent),    // 3: ascent
        valueToIndex.get(glyph.actualBoundingBoxDescent)    // 4: descent
      ];

      // TIER 5+6b: Tuplet compression based on redundancy patterns
      // Cascading strategy (most-frequent-first):
      // Strategy 1: w===r (most frequent, 48%)
      // Strategy 2: l===d (combined with #1, 43%)
      // Strategy 3: l===common (combined with #1+#2, ~40% of those)
      const widthEqualsRight = indices[0] === indices[2];      // w === r
      const leftEqualsDescent = indices[1] === indices[4];     // l === d
      const leftEqualsCommon = indices[1] === commonLeftIndex; // l === common left

      if (widthEqualsRight && leftEqualsDescent && leftEqualsCommon) {
        // Case D: All three strategies apply - compress to 2 elements [w, a]
        // Decompression: [w, a] ‚Üí [w, CL, w, a, CL]
        return [indices[0], indices[3]];
      }
      else if (widthEqualsRight && leftEqualsDescent) {
        // Case C: First two strategies apply - compress to 3 elements [w, l, a]
        // Decompression: [w, l, a] ‚Üí [w, l, w, a, l]
        return [indices[0], indices[1], indices[3]];
      }
      else if (widthEqualsRight) {
        // Case B: First strategy only - compress to 4 elements [w, l, a, d]
        // Decompression: [w, l, a, d] ‚Üí [w, l, w, a, d]
        return [indices[0], indices[1], indices[3], indices[4]];
      }
      else {
        // Case A: No compression - keep all 5 elements [w, l, r, a, d]
        return indices;
      }
    });

    // Log compression statistics
    let caseD = 0, caseC = 0, caseB = 0, caseA = 0;
    for (const tuplet of indexedGlyphs) {
      if (tuplet.length === 2) caseD++;
      else if (tuplet.length === 3) caseC++;
      else if (tuplet.length === 4) caseB++;
      else caseA++;
    }
    const savedIndices = 1020 - (caseD * 2 + caseC * 3 + caseB * 4 + caseA * 5);
    console.debug(`üóúÔ∏è  Tuplet compression: ${caseD} √ó 2-elem, ${caseC} √ó 3-elem, ${caseB} √ó 4-elem, ${caseA} √ó 5-elem (saved ${savedIndices} indices)`);

    return {
      valueLookup,
      indexedGlyphs,
      commonLeftIndex  // TIER 6b: Return common left index for file format
    };
  }

  /**
   * Creates tuplet lookup table and replaces glyph index arrays with tuplet indices
   * TIER 5 OPTIMIZATION: Tuplet deduplication - many glyphs share identical index patterns
   *
   * Strategy: Assign shortest indices to tuplets with highest (JSON_length √ó occurrences)
   * This works on top of Tier 5a pattern compression (variable-length tuplets)
   *
   * @param {Array<Array<number>>} indexedGlyphs - Array of index tuplets (may be variable length 3-5)
   * @returns {Object} Object with tupletLookup array and tupletIndices array
   * @private
   */
  static #createTupletLookupTable(indexedGlyphs) {
    // Step 1: Collect unique tuplets and count occurrences
    const tupletOccurrences = new Map(); // JSON string -> {tuplet, count}

    for (const tuplet of indexedGlyphs) {
      const key = JSON.stringify(tuplet);
      if (!tupletOccurrences.has(key)) {
        tupletOccurrences.set(key, { tuplet, count: 0 });
      }
      tupletOccurrences.get(key).count++;
    }

    // Step 2: Calculate scores and sort by savings potential
    // Score = JSON_length √ó occurrences (higher = more savings from short index)
    const tupletScores = Array.from(tupletOccurrences.values()).map(({tuplet, count}) => {
      const stringLength = JSON.stringify(tuplet).length;
      const score = stringLength * count;
      return { tuplet, count, stringLength, score };
    });

    // Sort by score DESCENDING (highest savings first)
    // Top 10 tuplets get indices 0-9 (1 char each)
    // Next 90 tuplets get indices 10-99 (2 chars each)
    // Remaining tuplets get indices 100+ (3+ chars each)
    tupletScores.sort((a, b) => b.score - a.score);

    // Step 3: Create tuplet lookup table (sorted by score for optimal indexing)
    const tupletLookup = tupletScores.map(ts => ts.tuplet);

    // Step 4: Create tuplet-to-index map for fast lookup
    const tupletToIndex = new Map();
    tupletLookup.forEach((tuplet, index) => {
      const key = JSON.stringify(tuplet);
      tupletToIndex.set(key, index);
    });

    // Step 5: Convert glyph tuplets to single tuplet indices
    const tupletIndices = indexedGlyphs.map(tuplet => {
      const key = JSON.stringify(tuplet);
      return tupletToIndex.get(key);
    });

    // Log compression statistics
    const uniqueTuplets = tupletLookup.length;
    const totalGlyphs = indexedGlyphs.length;
    const deduplicationPercent = ((1 - uniqueTuplets / totalGlyphs) * 100).toFixed(1);

    console.debug(`üóúÔ∏è  Tuplet deduplication: ${totalGlyphs} glyphs ‚Üí ${uniqueTuplets} unique tuplets (${deduplicationPercent}% deduplicated)`);

    return {
      tupletLookup,
      tupletIndices
    };
  }

  /**
   * Creates kerning value lookup table and replaces kerning values with indices
   * TIER 4 OPTIMIZATION: Value indexing for kerning table
   *
   * Strategy: Same as glyph value indexing - assign shortest indices to values
   * with highest (occurrence_count √ó string_length)
   *
   * @param {Object} kerningTable - Original kerning table with numeric values
   * @returns {Object} Object with kerningValueLookup array and indexedKerningTable
   * @private
   */
  static #createKerningValueLookupTable(kerningTable) {
    // Step 1: Collect all unique kerning values and count occurrences
    const valueOccurrences = new Map();

    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      for (const [rightChar, value] of Object.entries(pairs)) {
        valueOccurrences.set(value, (valueOccurrences.get(value) || 0) + 1);
      }
    }

    // Step 2: Calculate scores and sort by savings potential
    const valueScores = Array.from(valueOccurrences.entries()).map(([value, count]) => {
      const stringLength = JSON.stringify(value).length;
      const score = count * stringLength;
      return { value, count, stringLength, score };
    });

    // Sort by score DESCENDING (highest savings first)
    valueScores.sort((a, b) => b.score - a.score);

    // Step 3: Create kerning value lookup table
    const kerningValueLookup = valueScores.map(vs => vs.value);

    // Step 4: Create value-to-index map
    const valueToIndex = new Map();
    kerningValueLookup.forEach((value, index) => {
      valueToIndex.set(value, index);
    });

    // Step 5: Apply 2D compression with indexed values
    // First, replace all values with indices
    const indexedTable = {};
    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      indexedTable[leftChar] = {};
      for (const [rightChar, value] of Object.entries(pairs)) {
        indexedTable[leftChar][rightChar] = valueToIndex.get(value);
      }
    }

    // Then apply 2D range compression on the indexed table
    const indexedKerningTable = this.#minifyKerningTable(indexedTable);

    return {
      kerningValueLookup,
      indexedKerningTable
    };
  }

  /**
   * Converts glyph metrics objects to compact arrays
   * TIER 2 OPTIMIZATION: Returns array of arrays (removes character keys, uses position instead)
   * Array format: [width, actualBoundingBoxLeft, actualBoundingBoxRight, actualBoundingBoxAscent, actualBoundingBoxDescent]
   * Always uses CHARACTER_SET order (all 204 characters)
   * @deprecated This method is replaced by #createValueLookupTable (Tier 4 optimization)
   * @private
   */
  static #minifyCharacterMetrics(characterMetrics) {
    // Convert to array of arrays in CHARACTER_SET order
    // IMPORTANT: Must iterate through CHARACTER_SET, not Object.keys/values
    // because JavaScript reorders numeric string keys ("0"-"9")
    return Array.from(CHARACTER_SET).map(char => {
      const glyph = characterMetrics[char];
      return [
        glyph.width,
        glyph.actualBoundingBoxLeft,
        glyph.actualBoundingBoxRight,
        glyph.actualBoundingBoxAscent,
        glyph.actualBoundingBoxDescent
      ];
    });
  }
  
  /**
   * Minifies kerning table using two-dimensional range notation
   * TIER 3 OPTIMIZATION: Two-pass compression
   *   Pass 1 (right-side): {"A":{"0":20,"1":20}} ‚Üí {"A":{"0-1":20}}
   *   Pass 2 (left-side):  {"A":{"s":20},"B":{"s":20}} ‚Üí {"A-B":{"s":20}}
   * Always uses CHARACTER_SET for range compression
   * @param {Object} kerningTable - Kerning table to minify
   * @private
   */
  static #minifyKerningTable(kerningTable) {
    // PASS 1: Compress right side (characters that follow)
    const rightCompressed = {};
    for (const [leftChar, pairs] of Object.entries(kerningTable)) {
      rightCompressed[leftChar] = this.#compressKerningPairs(pairs);
    }

    // PASS 2: Compress left side (characters that come before)
    const leftCompressed = this.#compressLeftSide(rightCompressed);

    return leftCompressed;
  }

  /**
   * Compresses kerning pairs by grouping ALL characters with same value (sequential or not)
   * TIER 6b OPTIMIZATION: Advanced kerning compression
   *
   * Groups all characters with same value into compact string notation:
   * - Individual characters: "abc"
   * - Ranges (3+ consecutive): "a-z"
   * - Mixed: "a-eg-ijk" (range a-e, then g, then range g-i, then j, then k)
   *
   * Special dash handling:
   * - Dash at START is literal: "-abc" means dash, a, b, c
   * - Dash in MIDDLE is range: "a-c" means range from a to c
   *
   * Example: {" ":1,",":1,".":1,"a":1,"c":1,"d":1,"e":1} ‚Üí {" ,.ac-e":1}
   *
   * Always uses CHARACTER_SET for range compression
   * @param {Object} pairs - Kerning pairs like {"0":20,"1":20,"2":20,...}
   * @returns {Object} Compressed pairs like {" ,.ac-e":20}
   * @private
   */
  static #compressKerningPairs(pairs) {
    if (Object.keys(pairs).length === 0) return {};

    // Build map of value -> array of character indices
    const valueToIndices = {};

    for (const [char, value] of Object.entries(pairs)) {
      const index = CHARACTER_SET.indexOf(char);
      if (index === -1) {
        console.warn(`Character "${char}" not found in CHARACTER_SET, skipping`);
        continue;
      }

      if (!valueToIndices[value]) {
        valueToIndices[value] = [];
      }
      valueToIndices[value].push(index);
    }

    // For each value, build compact string notation
    const compressed = {};

    for (const [value, indices] of Object.entries(valueToIndices)) {
      // Sort indices
      indices.sort((a, b) => a - b);

      // Build compact string notation
      const compactString = this.#buildCompactCharString(indices);

      // Store with compact string as key
      compressed[compactString] = parseFloat(value);
    }

    return compressed;
  }

  /**
   * Builds compact character string from indices
   * TIER 6b OPTIMIZATION: Groups all characters (sequential or not)
   *
   * Special handling:
   * - Dash character (index 13 in CHARACTER_SET): placed at beginning to avoid ambiguity
   * - Ranges of 3+: "a-z"
   * - Individual chars: "abc"
   * - Mixed: "-,.:;ac-egj-s"
   *
   * @param {number[]} indices - Sorted array of CHARACTER_SET indices
   * @returns {string} Compact string notation
   * @private
   */
  static #buildCompactCharString(indices) {
    const DASH_INDEX = CHARACTER_SET.indexOf('-');
    let result = '';

    // Check if dash is in the list - if so, handle it first
    const hasDash = indices.includes(DASH_INDEX);
    if (hasDash) {
      result = '-';
      // Remove dash from indices for processing
      indices = indices.filter(idx => idx !== DASH_INDEX);
    }

    // Find consecutive ranges
    const ranges = this.#findConsecutiveRanges(indices);

    // Build string from ranges
    for (const range of ranges) {
      if (range.start === range.end) {
        // Single character
        result += CHARACTER_SET[range.start];
      } else if (range.end === range.start + 1) {
        // Two characters - more efficient as separate (no dash needed)
        result += CHARACTER_SET[range.start];
        result += CHARACTER_SET[range.end];
      } else {
        // Range of 3+ characters - use dash notation
        result += CHARACTER_SET[range.start];
        result += '-';
        result += CHARACTER_SET[range.end];
      }
    }

    return result;
  }

  /**
   * Finds consecutive ranges in sorted array of indices
   * @param {number[]} indices - Sorted array of indices
   * @returns {Array<{start: number, end: number}>} Array of range objects
   * @private
   */
  static #findConsecutiveRanges(indices) {
    if (indices.length === 0) return [];

    const ranges = [];
    let rangeStart = indices[0];
    let rangeEnd = indices[0];

    for (let i = 1; i < indices.length; i++) {
      if (indices[i] === rangeEnd + 1) {
        // Consecutive, extend range
        rangeEnd = indices[i];
      } else {
        // Gap found, save current range and start new one
        ranges.push({ start: rangeStart, end: rangeEnd });
        rangeStart = indices[i];
        rangeEnd = indices[i];
      }
    }

    // Save final range
    ranges.push({ start: rangeStart, end: rangeEnd });

    return ranges;
  }

  /**
   * Compresses left side of kerning table (characters that come before)
   * TIER 3 OPTIMIZATION: Two-dimensional compression pass 2
   * Groups left characters with identical right-side objects and compresses to ranges
   * Always uses CHARACTER_SET for range compression
   * Example: {"A":{"s":20},"B":{"s":20},"C":{"s":20}} ‚Üí {"A-C":{"s":20}}
   * @param {Object} kerningTable - Right-compressed kerning table
   * @returns {Object} Left-compressed kerning table
   * @private
   */
  static #compressLeftSide(kerningTable) {
    // Group left characters by their right-side object signature
    const rightSideToLeftChars = {};

    for (const [leftChar, rightSideObj] of Object.entries(kerningTable)) {
      const signature = JSON.stringify(rightSideObj);
      if (!rightSideToLeftChars[signature]) {
        rightSideToLeftChars[signature] = [];
      }
      rightSideToLeftChars[signature].push(leftChar);
    }

    // For each group, find consecutive ranges and compress
    const compressed = {};

    for (const [signature, leftChars] of Object.entries(rightSideToLeftChars)) {
      const rightSideObj = JSON.parse(signature);

      // Convert left characters to indices in CHARACTER_SET
      const indices = leftChars
        .map(char => CHARACTER_SET.indexOf(char))
        .filter(idx => idx !== -1)
        .sort((a, b) => a - b);

      // Find consecutive ranges using existing helper
      const ranges = this.#findConsecutiveRanges(indices);

      // Convert ranges to notation (3+ chars ‚Üí range, 1-2 chars ‚Üí keep separate)
      for (const range of ranges) {
        if (range.start === range.end) {
          // Single character
          compressed[CHARACTER_SET[range.start]] = rightSideObj;
        } else if (range.end === range.start + 1) {
          // Two characters - more efficient as separate entries
          compressed[CHARACTER_SET[range.start]] = rightSideObj;
          compressed[CHARACTER_SET[range.end]] = rightSideObj;
        } else {
          // Range of 3+ characters
          const startChar = CHARACTER_SET[range.start];
          const endChar = CHARACTER_SET[range.end];
          compressed[`${startChar}-${endChar}`] = rightSideObj;
        }
      }
    }

    return compressed;
  }

  /**
   * Converts array of float values to integers by multiplying by 10000
   * TIER 6 OPTIMIZATION: Value to integer conversion
   *
   * @param {number[]} values - Array of float values
   * @returns {number[]} Array of integer values
   * @private
   */
  static #convertValuesToIntegers(values) {
    return values.map(val => {
      // Handle integers (no decimal point)
      if (Number.isInteger(val)) {
        return val * 10000;
      }
      // Handle floats - multiply and round to avoid floating point errors
      return Math.round(val * 10000);
    });
  }

  /**
   * Flattens baseline object to array
   * TIER 6 OPTIMIZATION: Baseline object ‚Üí array
   *
   * @param {Object} baseline - Baseline object with {fba, fbd, hb, ab, ib, pd}
   * @returns {number[]} Array [fba, fbd, hb, ab, ib, pd]
   * @private
   */
  static #flattenBaseline(baseline) {
    // Fixed order: fba, fbd, hb, ab, ib, pd
    return [
      baseline.fba,
      baseline.fbd,
      baseline.hb,
      baseline.ab,
      baseline.ib,
      baseline.pd
    ];
  }

  /**
   * Flattens tuplet arrays using negative delimiter format
   * TIER 6b OPTIMIZATION: Tuplet array flattening with negative delimiters
   *
   * Uses negative on last element to mark tuplet boundary.
   * Shifts indices by 1 to avoid -0 problem in JSON (0 becomes 1, 1 becomes 2, etc.)
   *
   * Converts: [[2,1,14],[0,1,15,7]] ‚Üí [3,2,-15,1,2,16,-8]
   * Each tuplet ends with a negative number (saves 1 char per tuplet vs length-prefix)
   *
   * @param {Array<Array<number>>} tuplets - Array of tuplet arrays (0-based indices)
   * @returns {number[]} Flattened array with negative delimiters (1-based indices)
   * @private
   */
  static #flattenTuplets(tuplets) {
    const flattened = [];
    for (const tuplet of tuplets) {
      // Shift all indices by 1 (to avoid -0 problem) and negate the last one
      for (let i = 0; i < tuplet.length - 1; i++) {
        flattened.push(tuplet[i] + 1);  // Add 1 to shift from 0-based to 1-based
      }
      // Last element: add 1 and negate to mark end of tuplet
      flattened.push(-(tuplet[tuplet.length - 1] + 1));
    }
    return flattened;
  }

}
// ============================================================================
// METRICS EXPANDER
// Used by MetricsMinifier.minifyWithVerification() for roundtrip checks
// ============================================================================

// Static utility class for expanding minified font metrics data (runtime only)
// Converts compact format back to FontMetrics instances for use by the rendering engine
// NOTE: Requires src/runtime/CHARACTER_SET.js to be loaded first

class MetricsExpander {
  // Private constructor - prevent instantiation following Effective Java patterns
  constructor() {
    throw new Error('MetricsExpander cannot be instantiated - use static methods');
  }

  /**
   * TIER 6c OPTIMIZATION: Decode base64 string to array of integers
   * Reverses the base64 byte encoding from MetricsMinifier
   *
   * @param {string} base64 - Base64 encoded string
   * @returns {Array<number>} Array of integers (0-255)
   */
  static #decodeFromBase64Bytes(base64) {
    // In browser: use atob
    // In Node.js: use Buffer
    let bytes;

    if (typeof Buffer !== 'undefined') {
      // Node.js environment
      bytes = Buffer.from(base64, 'base64');
    } else {
      // Browser environment
      const binary = atob(base64);
      bytes = new Uint8Array(binary.length);
      for (let i = 0; i < binary.length; i++) {
        bytes[i] = binary.charCodeAt(i);
      }
    }

    return Array.from(bytes);
  }

  /**
   * TIER 6c OPTIMIZATION: Decode varint+zigzag+base64 to signed integers
   * Reverses the VarInt encoding from MetricsMinifier
   *
   * @param {string} base64 - Base64 encoded varint bytes
   * @returns {Array<number>} Array of signed integers
   */
  static #decodeVarInts(base64) {
    const bytes = this.#decodeFromBase64Bytes(base64);
    const integers = [];
    let i = 0;

    while (i < bytes.length) {
      // Decode VarInt: 7 bits per byte, MSB indicates continuation
      let value = 0;
      let shift = 0;
      let byte;

      do {
        byte = bytes[i++];
        value |= (byte & 0x7F) << shift;
        shift += 7;
      } while (byte & 0x80);

      // Zigzag decoding: convert unsigned back to signed
      // 0‚Üí0, 1‚Üí-1, 2‚Üí1, 3‚Üí-2, 4‚Üí2, ...
      const signed = (value & 1) ? -(value + 1) / 2 : value / 2;
      integers.push(signed);
    }

    return integers;
  }

  /**
   * TIER 7 OPTIMIZATION: Decompress value lookup array from delta encoding + base64
   *
   * Reverses the compression:
   * 1. Decode base64 ‚Üí varint ‚Üí zigzag ‚Üí deltas
   * 2. Reconstruct sorted values from deltas
   * 3. Return as unsorted array (order doesn't matter for lookup)
   *
   * @param {string} base64 - Base64 encoded delta-compressed string
   * @returns {Array<number>} Array of metric value integers
   */
  static #decompressValueArray(base64) {
    // Decode base64 ‚Üí deltas
    const deltas = this.#decodeVarInts(base64);

    // Reconstruct sorted values from deltas
    const sorted = [deltas[0]]; // First value is absolute
    for (let i = 1; i < deltas.length; i++) {
      sorted.push(sorted[i - 1] + deltas[i]);
    }

    // Return as-is (order doesn't matter for value lookup)
    // The indices in tuplets refer to sorted positions
    return sorted;
  }

  /**
   * Expands minified metrics back to FontMetrics instance for runtime use
   * TIER 7 FORMAT (backward compatible with Tier 6c)
   *
   * @param {Array} minified - Minified metrics array [kv, k, b, v, t, g, s, cl]
   *   - v can be array (Tier 6c) or base64 string (Tier 7)
   * @returns {FontMetrics} FontMetrics instance with expanded data
   * @throws {Error} If invalid format detected
   */
  static expand(minified) {
    // Check if FontMetrics class is available
    if (typeof FontMetrics === 'undefined') {
      throw new Error('FontMetrics class not found. Please ensure FontMetrics.js is loaded before MetricsExpander.js');
    }

    // Validate Tier 6c format: 8-element array only
    if (!Array.isArray(minified) || minified.length !== 8) {
      throw new Error(
        `Invalid format - expected 8-element array (Tier 6c), got ${typeof minified === 'object' ? 'array' : typeof minified} with ${minified?.length || 0} elements.\n` +
        `Please regenerate font assets with the current version.`
      );
    }

    // Extract values from Tier 6c/7 array format
    let [kv, k, b, v, t, g, s, cl] = minified;

    // Convert integer values back to floats (divide by 10000)
    kv = this.#convertIntegersToValues(kv);

    // TIER 7: Handle value lookup array - can be array (Tier 6c) or base64 string (Tier 7)
    if (typeof v === 'string') {
      // Tier 7: Decompress from delta-encoded base64
      v = this.#decompressValueArray(v);
      v = this.#convertIntegersToValues(v);
    } else if (Array.isArray(v)) {
      // Tier 6c: Already an array of integers
      v = this.#convertIntegersToValues(v);
    } else {
      throw new Error('Invalid value lookup format - expected array or string');
    }

    // Unflatten baseline array to object
    b = this.#unflattenBaseline(b);

    // Decode base64-encoded binary data
    // t = VarInt+zigzag encoded flattened tuplets
    // g = byte-encoded tuplet indices
    t = this.#decodeVarInts(t);
    g = this.#decodeFromBase64Bytes(g);

    // Unflatten tuplet data from negative-delimiter format
    t = this.#unflattenTuplets(t);

    const expandedData = {
      kerningTable: this.#expandKerningTable(k, kv),
      characterMetrics: this.#expandCharacterMetrics(g, b, v, t, cl),
      spaceAdvancementOverrideForSmallSizesInPx: s
    };

    // Verify pixelDensity was preserved
    const firstChar = Object.keys(expandedData.characterMetrics)[0];
    const pixelDensity = expandedData.characterMetrics[firstChar]?.pixelDensity;
    console.debug(`üîç MetricsExpander: Restored pixelDensity=${pixelDensity} for ${Object.keys(expandedData.characterMetrics).length} characters`);

    return new FontMetrics(expandedData);
  }
  
  /**
   * Expands kerning table with range notation support
   * TIER 3 OPTIMIZATION: Two-dimensional expansion (reverse order of compression)
   * TIER 4 OPTIMIZATION: Value indexing (looks up actual kerning values from indices)
   *   Pass 1 (left-side):  {"A-B":{"s":0}} ‚Üí {"A":{"s":0},"B":{"s":0}}
   *   Pass 2 (right-side): {"A":{"0-1":0}} ‚Üí {"A":{"0":0,"1":0}}
   *   Pass 3 (values):     {"A":{"s":0}} ‚Üí {"A":{"s":20}} (lookup from kerningValueLookup[0])
   * Always uses CHARACTER_SET for range expansion
   * Later entries override earlier ones, allowing exceptions to ranges
   * @param {Object} minified - Minified kerning table with indexed values
   * @param {Array} kerningValueLookup - Value lookup table for kerning values
   * @private
   */
  static #expandKerningTable(minified, kerningValueLookup) {
    // PASS 1: Expand left side (characters that come before)
    const leftExpanded = this.#expandLeftSide(minified);

    // PASS 2: Expand right side (characters that follow)
    const rangeExpanded = {};
    for (const [leftChar, pairs] of Object.entries(leftExpanded)) {
      rangeExpanded[leftChar] = this.#expandKerningPairs(pairs);
    }

    // PASS 3 (TIER 4): Replace all indices with actual values from lookup table
    const expanded = {};
    for (const [leftChar, pairs] of Object.entries(rangeExpanded)) {
      expanded[leftChar] = {};
      for (const [rightChar, index] of Object.entries(pairs)) {
        expanded[leftChar][rightChar] = kerningValueLookup[index];
      }
    }

    return expanded;
  }

  /**
   * Expands left side of kerning table (characters that come before)
   * TIER 3 OPTIMIZATION: Two-dimensional expansion pass 1
   * Handles left-side range notation like "A-C":{"s":20} ‚Üí {"A":{"s":20},"B":{"s":20},"C":{"s":20}}
   * Always uses CHARACTER_SET for range expansion
   * @param {Object} minified - Minified kerning table with potential left-side ranges
   * @returns {Object} Left-expanded kerning table
   * @private
   */
  static #expandLeftSide(minified) {
    const expanded = {};

    // Process entries in order so later entries can override earlier ones
    for (const [key, rightSideObj] of Object.entries(minified)) {
      if (key.includes('-') && key.length >= 3) {
        // Potential range notation (e.g., "A-Z" or "0-9")
        const hyphenIndex = key.indexOf('-');
        const startChar = key.substring(0, hyphenIndex);
        const endChar = key.substring(hyphenIndex + 1);

        // Check if both start and end are single characters in the character set
        if (startChar.length === 1 && endChar.length === 1) {
          const startIndex = CHARACTER_SET.indexOf(startChar);
          const endIndex = CHARACTER_SET.indexOf(endChar);

          if (startIndex !== -1 && endIndex !== -1 && startIndex <= endIndex) {
            // Valid range, expand it
            for (let i = startIndex; i <= endIndex; i++) {
              expanded[CHARACTER_SET[i]] = rightSideObj;
            }
            continue;
          }
        }
      }

      // Not a range, or invalid range - treat as literal character
      expanded[key] = rightSideObj;
    }

    return expanded;
  }

  /**
   * Expands kerning pairs from compact string notation to individual character pairs
   * TIER 6b OPTIMIZATION: Handles advanced compact notation with non-sequential grouping
   *
   * Parses compact strings like "-,.:;ac-egj-s" which means:
   * - Dash at START is literal
   * - Individual chars: comma, dot, colon, semicolon
   * - Ranges: a, c-e (c,d,e), g, j-s (j,k,l,m,n,o,p,q,r,s)
   *
   * Always uses CHARACTER_SET for range expansion
   * @param {Object} pairs - Compressed pairs like {"-,.:;ac-egj-s":20}
   * @returns {Object} Expanded pairs like {"-":20,",":20,".":20,...,"s":20}
   * @private
   */
  static #expandKerningPairs(pairs) {
    const expanded = {};

    // Process entries in order so later entries can override earlier ones
    for (const [key, value] of Object.entries(pairs)) {
      // Parse the compact string notation
      const chars = this.#parseCompactCharString(key);

      // Assign value to all parsed characters
      for (const char of chars) {
        expanded[char] = value;
      }
    }

    return expanded;
  }

  /**
   * Parses compact character string notation
   * TIER 6b OPTIMIZATION: Handles dash-at-start and range notation
   *
   * Format:
   * - First char is dash ‚Üí literal dash character
   * - "a-z" ‚Üí range from a to z
   * - "abc" ‚Üí individual characters a, b, c
   * - "-,.:;ac-egj-s" ‚Üí dash, comma, dot, colon, semicolon, a, c-e range, g, j-s range
   *
   * @param {string} compactStr - Compact string like "-,.:;ac-egj-s"
   * @returns {string[]} Array of individual characters
   * @private
   */
  static #parseCompactCharString(compactStr) {
    const chars = [];
    let i = 0;

    // Handle dash at start (literal)
    if (compactStr[0] === '-') {
      chars.push('-');
      i = 1;
    }

    // Parse rest of string
    while (i < compactStr.length) {
      const currentChar = compactStr[i];

      // Check if this is the start of a range pattern
      if (i + 2 < compactStr.length && compactStr[i + 1] === '-') {
        // Pattern: "X-Y" where X and Y are single characters
        const startChar = currentChar;
        const endChar = compactStr[i + 2];

        // Verify it's a valid range in CHARACTER_SET
        const startIndex = CHARACTER_SET.indexOf(startChar);
        const endIndex = CHARACTER_SET.indexOf(endChar);

        if (startIndex !== -1 && endIndex !== -1 && startIndex < endIndex) {
          // Valid range - expand it
          for (let j = startIndex; j <= endIndex; j++) {
            chars.push(CHARACTER_SET[j]);
          }
          i += 3; // Skip X, -, Y
        } else {
          // Not a valid range - treat as individual characters
          chars.push(currentChar);
          i++;
        }
      } else {
        // Individual character
        chars.push(currentChar);
        i++;
      }
    }

    return chars;
  }
  
  /**
   * Expands glyph metrics from arrays back to full objects
   * TIER 2 OPTIMIZATION: Reconstructs from array of arrays using CHARACTER_SET
   * TIER 4 OPTIMIZATION: Looks up actual values from indices using valueLookup table
   * TIER 5a OPTIMIZATION: Decompresses variable-length tuplets (2/3/4/5 elements)
   * TIER 5b OPTIMIZATION: Looks up tuplets from tuplet indices
   * TIER 6b OPTIMIZATION: 2-element tuplets using common left index
   *
   * Tuplet decompression (deterministic based on length):
   *   - Length 2: [w, a] ‚Üí [w, CL, w, a, CL]  (w===r AND l===CL AND d===CL)
   *   - Length 3: [w, l, a] ‚Üí [w, l, w, a, l]  (w===r AND l===d)
   *   - Length 4: [w, l, a, d] ‚Üí [w, l, w, a, d]  (w===r only)
   *   - Length 5: [w, l, r, a, d] (no decompression)
   *
   * Reconstructs full TextMetrics-compatible objects from compact arrays
   * Always uses CHARACTER_SET for character order
   * @param {Array} tupletIndices - Array of tuplet indices (single integers)
   * @param {Object} metricsCommonToAllCharacters - Common metrics shared across all characters
   * @param {Array} valueLookup - Value lookup table mapping indices to actual values
   * @param {Array} tupletLookup - Tuplet lookup table mapping tuplet indices to index arrays
   * @param {number} [commonLeftIndex] - Common left bounding box index (Tier 6b, optional)
   * @private
   */
  static #expandCharacterMetrics(tupletIndices, metricsCommonToAllCharacters, valueLookup, tupletLookup, commonLeftIndex) {
    const expanded = {};

    // Convert CHARACTER_SET string to array of characters
    const chars = Array.from(CHARACTER_SET);

    // Reconstruct object by mapping array positions to characters
    chars.forEach((char, index) => {
      // TIER 5b: Look up tuplet from tuplet index
      const tupletIndex = tupletIndices[index];
      const compressed = tupletLookup[tupletIndex];

      let indices;

      // TIER 5+6b: Decompress tuplet based on length
      if (compressed.length === 2) {
        // Case D (TIER 6b): [w, a] ‚Üí [w, CL, w, a, CL]
        // All three patterns: w===r AND l===CL AND d===CL
        if (commonLeftIndex === undefined) {
          throw new Error(
            `2-element tuplet found but no common left index provided.\n` +
            `Character "${char}" at index ${index}: [${compressed.join(',')}]\n` +
            `This indicates a corrupted Tier 6b font file. Please regenerate font assets.`
          );
        }
        indices = [
          compressed[0],    // width
          commonLeftIndex,  // left = common left
          compressed[0],    // right = width (pattern 1)
          compressed[1],    // ascent
          commonLeftIndex   // descent = common left (pattern 2)
        ];
      }
      else if (compressed.length === 3) {
        // Case C: [w, l, a] ‚Üí [w, l, w, a, l]
        // Both w===r and l===d
        indices = [
          compressed[0],  // width
          compressed[1],  // left
          compressed[0],  // right = width (pattern 1)
          compressed[2],  // ascent
          compressed[1]   // descent = left (pattern 2)
        ];
      }
      else if (compressed.length === 4) {
        // Case B: [w, l, a, d] ‚Üí [w, l, w, a, d]
        // Only w===r
        indices = [
          compressed[0],  // width
          compressed[1],  // left
          compressed[0],  // right = width (pattern 1)
          compressed[2],  // ascent
          compressed[3]   // descent
        ];
      }
      else if (compressed.length === 5) {
        // Case A: [w, l, r, a, d] - no decompression needed
        indices = compressed;
      }
      else {
        throw new Error(
          `Invalid glyph tuplet length for character "${char}" at index ${index}.\n` +
          `Expected 2, 3, 4, or 5 elements, got ${compressed.length}: [${compressed.join(',')}]\n` +
          `This indicates a corrupted font file. Please regenerate font assets.`
        );
      }

      // TIER 4: Look up actual values from indices
      const width = valueLookup[indices[0]];
      const actualBoundingBoxLeft = valueLookup[indices[1]];
      const actualBoundingBoxRight = valueLookup[indices[2]];
      const actualBoundingBoxAscent = valueLookup[indices[3]];
      const actualBoundingBoxDescent = valueLookup[indices[4]];

      expanded[char] = {
        // Glyph-specific metrics looked up from value table
        width,
        actualBoundingBoxLeft,
        actualBoundingBoxRight,
        actualBoundingBoxAscent,
        actualBoundingBoxDescent,

        // Copy over the metrics common to all characters.
        // This is a bit of a waste of memory, however this object needs to
        // look as much as possible like a TextMetrics object, and this
        // is what it looks like.
        fontBoundingBoxAscent: metricsCommonToAllCharacters.fba,
        fontBoundingBoxDescent: metricsCommonToAllCharacters.fbd,
        emHeightAscent: metricsCommonToAllCharacters.fba,          // Same as fontBoundingBoxAscent
        emHeightDescent: metricsCommonToAllCharacters.fbd,         // Same as fontBoundingBoxDescent
        hangingBaseline: metricsCommonToAllCharacters.hb,
        alphabeticBaseline: metricsCommonToAllCharacters.ab,
        ideographicBaseline: metricsCommonToAllCharacters.ib,
        pixelDensity: metricsCommonToAllCharacters.pd              // pixelDensity (CRITICAL for atlas reconstruction)
      };
    });
    return expanded;
  }

  /**
   * Converts array of integer values back to floats by dividing by 10000
   * TIER 6 OPTIMIZATION: Integer to value conversion
   *
   * @param {number[]} integers - Array of integer values
   * @returns {number[]} Array of float values
   * @private
   */
  static #convertIntegersToValues(integers) {
    return integers.map(int => int / 10000);
  }

  /**
   * Unflattens baseline array back to object
   * TIER 6 OPTIMIZATION: Baseline array ‚Üí object
   *
   * @param {number[]} baselineArray - Array [fba, fbd, hb, ab, ib, pd]
   * @returns {Object} Baseline object with {fba, fbd, hb, ab, ib, pd}
   * @private
   */
  static #unflattenBaseline(baselineArray) {
    if (!Array.isArray(baselineArray) || baselineArray.length !== 6) {
      throw new Error(
        `Invalid baseline array - expected 6 elements, got ${baselineArray?.length}.\n` +
        `This indicates a corrupted font file. Please regenerate font assets.`
      );
    }

    // Fixed order: fba, fbd, hb, ab, ib, pd
    return {
      fba: baselineArray[0],
      fbd: baselineArray[1],
      hb: baselineArray[2],
      ab: baselineArray[3],
      ib: baselineArray[4],
      pd: baselineArray[5]
    };
  }

  /**
   * Unflattens tuplet data from negative delimiter format
   * TIER 6b OPTIMIZATION: Tuplet array unflattening with negative delimiters
   *
   * Parses negative-delimited format and shifts back to 0-based indices.
   * Negative numbers mark the end of each tuplet.
   *
   * Converts: [3,2,-15,1,2,16,-8] ‚Üí [[2,1,14],[0,1,15,7]]
   * Each tuplet ends with a negative number (1-based) which becomes last element (0-based)
   *
   * @param {number[]} flattened - Flattened array with negative delimiters (1-based indices)
   * @returns {Array<Array<number>>} Array of tuplet arrays (0-based indices)
   * @private
   */
  static #unflattenTuplets(flattened) {
    const tuplets = [];
    let currentTuplet = [];

    for (let i = 0; i < flattened.length; i++) {
      const value = flattened[i];

      if (value < 0) {
        // Negative marks end of tuplet
        // Negate back and subtract 1 to get 0-based index
        currentTuplet.push((-value) - 1);

        // Validate tuplet length
        if (currentTuplet.length < 2 || currentTuplet.length > 5) {
          throw new Error(
            `Invalid tuplet length ${currentTuplet.length} at position ${i}.\n` +
            `Expected 2, 3, 4, or 5. This indicates a corrupted font file.\n` +
            `Please regenerate font assets.`
          );
        }

        tuplets.push(currentTuplet);
        currentTuplet = [];
      } else {
        // Positive value: subtract 1 to get 0-based index
        currentTuplet.push(value - 1);
      }
    }

    // Check for incomplete tuplet at end
    if (currentTuplet.length > 0) {
      throw new Error(
        `Incomplete tuplet at end of data.\n` +
        `Found ${currentTuplet.length} elements without negative delimiter.\n` +
        `This indicates a corrupted font file. Please regenerate font assets.`
      );
    }

    return tuplets;
  }

}
// ============================================================================
// DEEP EQUAL UTILITY
// Used by verification logic to compare original vs expanded metrics
// ============================================================================

// Method 3: Custom recursive comparison
function deepEqual(obj1, obj2) {
  // Check if both are primitive values
  if (obj1 === obj2) return true;
  
  // Check if either is null or not an object
  if (typeof obj1 !== 'object' || obj1 === null ||
      typeof obj2 !== 'object' || obj2 === null) return false;
  
  // Get keys of both objects
  const keys1 = Object.keys(obj1);
  const keys2 = Object.keys(obj2);
  
  // Check if number of keys is different
  if (keys1.length !== keys2.length) return false;
  
  // Recursively compare all properties
  for (const key of keys1) {
      if (!keys2.includes(key)) return false;
      if (!deepEqual(obj1[key], obj2[key])) return false;
  }
  
  return true;
}
// ============================================================================
// MAIN SCRIPT LOGIC
// ============================================================================

// ============================================================================

function processFullMetricsFiles() {
  const fontAssetsDir = path.join(__dirname, '..', 'font-assets');
  const productionDir = fontAssetsDir; // Production files in same directory

  // Check if font-assets directory exists
  if (!fs.existsSync(fontAssetsDir)) {
    console.error('‚ùå font-assets/ directory not found');
    console.error('   Expected at:', fontAssetsDir);
    process.exit(1);
  }

  // Find all -full.js files
  const files = fs.readdirSync(fontAssetsDir).filter(f => f.endsWith('-full.js'));

  if (files.length === 0) {
    console.log('\n‚ö†Ô∏è  No *-full.js files found in font-assets/');
    console.log('');
    console.log('To generate full metrics files:');
    console.log('  1. Open public/font-assets-builder.html in browser');
    console.log('  2. Configure your font settings');
    console.log('  3. Check "Include non-minified metrics files"');
    console.log('  4. Click "Download font assets"');
    console.log('  5. Extract fontAssets.zip to font-assets/');
    console.log('');
    process.exit(0);
  }

  console.log('\nüî¨ Metrics Minification & Verification');
  console.log('‚ïê'.repeat(60));
  console.log(`Found ${files.length} full metrics file(s) to process`);
  if (options.verifyExact) {
    console.log('üîç Exact verification: ENABLED (comparing with production files)');
  }
  console.log('');

  let successCount = 0;
  let errorCount = 0;
  const results = [];

  for (const filename of files) {
    const fullPath = path.join(fontAssetsDir, filename);

    try {
      // Read file content
      const content = fs.readFileSync(fullPath, 'utf8');

      // Extract metricsData using capture mechanism
      // The -full.js files have format (Tier 6):
      // BitmapText.r('compressedID', {...metricsData...})
      // OR legacy format:
      // BitmapText.registerMetrics('idString', {...metricsData...})
      let capturedIdString = null;
      let capturedData = null;

      // Create mock BitmapText object to capture data
      const BitmapText = {
        registerMetrics: function(idString, data) {
          capturedIdString = idString;
          capturedData = data;
        },
        r: function(densityOrIdString, fontFamilyOrData, styleIdx, weightIdx, size, data) {
          // TIER 6b: Support both old string format and new multi-parameter format
          if (arguments.length === 2) {
            // Old format: r(idString, data)
            capturedIdString = densityOrIdString;
            capturedData = fontFamilyOrData;
          } else if (arguments.length === 6) {
            // New multi-parameter format: r(density, fontFamily, styleIdx, weightIdx, size, data)
            const density = densityOrIdString;
            const fontFamily = fontFamilyOrData;

            // Reconstruct full ID string from parameters
            // Convert numeric indices back to strings
            const styleStr = styleIdx === 0 ? 'normal' : (styleIdx === 1 ? 'italic' : 'oblique');
            const weightStr = weightIdx === 0 ? 'normal' : (weightIdx === 1 ? 'bold' : String(weightIdx));

            // Parse density and size to handle both integer and decimal formats
            const densityParts = String(density).split('.');
            const densityInt = densityParts[0];
            const densityFrac = densityParts[1] || '0';

            const sizeParts = String(size).split('.');
            const sizeInt = sizeParts[0];
            const sizeFrac = sizeParts[1] || '0';

            // Reconstruct full ID: density-{d}-{frac}-{family}-style-{style}-weight-{weight}-size-{s}-{frac}
            capturedIdString = `density-${densityInt}-${densityFrac}-${fontFamily}-style-${styleStr}-weight-${weightStr}-size-${sizeInt}-${sizeFrac}`;
            capturedData = data;
          } else {
            throw new Error(`Unexpected parameter count: ${arguments.length}`);
          }
        }
      };

      // Evaluate the file to trigger registerMetrics/r call
      eval(content);

      if (!capturedData) {
        throw new Error('Failed to extract metricsData from file (registerMetrics/r not called)');
      }

      // TIER 6: Decompress ID if it's in compressed format
      if (capturedIdString.includes(',')) {
        // Compressed format - decompress it
        capturedIdString = MetricsMinifier.decompressFontID(capturedIdString);
      }

      // Calculate original size
      const originalSize = JSON.stringify(capturedData).length;

      // Run minification with automatic roundtrip verification
      // This calls MetricsMinifier.minifyWithVerification() which:
      // 1. Minifies the data
      // 2. Expands it back using MetricsExpander
      // 3. Compares with original using deep-equal
      // 4. Throws error if mismatch
      // 5. Returns minified data on success
      const minified = MetricsMinifier.minifyWithVerification(capturedData);

      // Calculate minified size
      const minifiedSize = JSON.stringify(minified).length;
      const reduction = ((1 - minifiedSize / originalSize) * 100).toFixed(1);
      const savedBytes = originalSize - minifiedSize;

      // Generate output filename
      // Input:  metrics-density-1-0-Arial-style-normal-weight-normal-size-18-0-full.js
      // Output: metrics-density-1-0-Arial-style-normal-weight-normal-size-18-0-full-minified.js
      const baseFilename = filename.replace('-full.js', '');
      const outputFilename = `${baseFilename}-full-minified.js`;
      const outputPath = path.join(fontAssetsDir, outputFilename);

      // TIER 6b: Decompose font ID for multi-parameter format
      const parts = capturedIdString.split('-');
      const density = parts[1] + (parts[2] === '0' ? '' : '.' + parts[2]); // "1" or "1.5"
      const fontFamilyFromID = parts[3];
      const styleFromID = parts[5]; // "normal", "italic", "oblique"
      const weightFromID = parts[7]; // "normal", "bold", or numeric
      const sizeStr = parts[9] + (parts[10] === '0' ? '' : '.' + parts[10]); // "18" or "18.5"

      // Compress style and weight to indices
      const styleIdx = styleFromID === 'normal' ? 0 : (styleFromID === 'italic' ? 1 : 2);
      const weightIdx = weightFromID === 'normal' ? 0 : (weightFromID === 'bold' ? 1 : weightFromID);

      // Write minified version with TIER 7 production wrapper
      // TIER 6b: Use 'r' shorthand with multi-parameter format
      // TIER 7: Remove safety checks - assume BitmapText exists (private library, saves ~46 bytes)
      // Must match: BitmapText.r(1,'Arial',0,0,18,[...])
      const jsContent = `BitmapText.r(${density},'${fontFamilyFromID}',${styleIdx},${weightIdx},${sizeStr},${JSON.stringify(minified)})`;
      fs.writeFileSync(outputPath, jsContent, 'utf8');

      // Optional: Verify exact match with production file
      let exactMatch = null;
      if (options.verifyExact) {
        // Find corresponding production file (without -full suffix)
        const productionFilename = filename.replace('-full.js', '.js');
        const productionPath = path.join(productionDir, productionFilename);

        if (fs.existsSync(productionPath)) {
          const productionContent = fs.readFileSync(productionPath, 'utf8');
          exactMatch = (jsContent === productionContent);
        } else {
          exactMatch = 'no-production-file';
        }
      }

      results.push({
        input: filename,
        output: outputFilename,
        originalSize,
        minifiedSize,
        reduction,
        savedBytes,
        exactMatch,
        status: 'success'
      });

      console.log(`‚úÖ ${filename}`);
      console.log(`   ‚Üí ${outputFilename}`);
      console.log(`   ID: ${capturedIdString}`);
      console.log(`   Original: ${originalSize.toLocaleString()} chars`);
      console.log(`   Minified: ${minifiedSize.toLocaleString()} chars`);
      console.log(`   Saved: ${savedBytes.toLocaleString()} chars (${reduction}% reduction)`);
      console.log(`   ‚úì Roundtrip verification passed`);

      if (options.verifyExact) {
        if (exactMatch === true) {
          console.log(`   ‚úì Exact match with production file`);
        } else if (exactMatch === false) {
          console.log(`   ‚ö†Ô∏è  Output differs from production file`);
        } else if (exactMatch === 'no-production-file') {
          console.log(`   ‚ÑπÔ∏è  No production file to compare (${filename.replace('-full.js', '.js')} not found)`);
        }
      }

      console.log('');

      successCount++;

    } catch (error) {
      results.push({
        input: filename,
        status: 'error',
        error: error.message
      });

      console.error(`‚ùå ${filename}`);
      console.error(`   Error: ${error.message}`);
      if (error.stack) {
        // Show first few lines of stack for debugging
        const stackLines = error.stack.split('\n').slice(0, 3).join('\n');
        console.error(`   Stack: ${stackLines}`);
      }
      console.error('');

      errorCount++;
    }
  }

  // Print summary
  console.log('‚ïê'.repeat(60));
  console.log(`üìä Summary: ${successCount} successful, ${errorCount} error(s)`);
  console.log('‚ïê'.repeat(60));

  if (successCount > 0) {
    console.log('\n‚úÖ Successfully minified files:');
    const successResults = results.filter(r => r.status === 'success');

    // Calculate totals
    let totalOriginal = 0;
    let totalMinified = 0;

    successResults.forEach(r => {
      totalOriginal += r.originalSize;
      totalMinified += r.minifiedSize;
      console.log(`   ${r.output}`);
      console.log(`     ${r.originalSize.toLocaleString()} ‚Üí ${r.minifiedSize.toLocaleString()} chars (${r.reduction}% reduction)`);
    });

    const totalSaved = totalOriginal - totalMinified;
    const totalReduction = ((1 - totalMinified / totalOriginal) * 100).toFixed(1);

    console.log('');
    console.log(`   Total: ${totalOriginal.toLocaleString()} ‚Üí ${totalMinified.toLocaleString()} chars`);
    console.log(`   Saved: ${totalSaved.toLocaleString()} chars (${totalReduction}% overall reduction)`);

    // Report exact match results if verification was enabled
    if (options.verifyExact) {
      const exactMatches = successResults.filter(r => r.exactMatch === true).length;
      const mismatches = successResults.filter(r => r.exactMatch === false).length;
      const noProductionFile = successResults.filter(r => r.exactMatch === 'no-production-file').length;

      console.log('');
      console.log('üîç Exact Verification Results:');
      if (exactMatches > 0) {
        console.log(`   ‚úì ${exactMatches} file(s) match production exactly`);
      }
      if (mismatches > 0) {
        console.log(`   ‚ö†Ô∏è  ${mismatches} file(s) differ from production`);
      }
      if (noProductionFile > 0) {
        console.log(`   ‚ÑπÔ∏è  ${noProductionFile} file(s) have no production file to compare`);
      }
    }
  }

  if (errorCount > 0) {
    console.log('\n‚ùå Errors:');
    results.filter(r => r.status === 'error').forEach(r => {
      console.log(`   ${r.input}: ${r.error}`);
    });
  }

  console.log('\nüí° Output files can be used to test different minification strategies');
  console.log('   by modifying MetricsMinifier.js and rebuilding this tool.');
  console.log('');
  if (!options.verifyExact) {
    console.log('   Tip: Use --verify-exact to compare with production files');
    console.log('   (useful for validating the tool produces identical output).');
    console.log('');
  }

  process.exit(errorCount > 0 ? 1 : 0);
}

// Run main function
processFullMetricsFiles();

